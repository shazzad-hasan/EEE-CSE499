{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm.notebook import tqdm \n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Activation, Flatten, Input, BatchNormalization, GlobalAveragePooling2D, Add, Conv2D, AveragePooling2D, \n",
    "    LeakyReLU, Concatenate \n",
    ")\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.applications as tfa\n",
    "import efficientnet.tfkeras as efn\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 8\n",
    "LR = 0.003\n",
    "SAVE_BEST = True\n",
    "MODEL_CLASS = 'b5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/shazz/Deep_Learning/Kaggle/input/osic-pulmonary-fibrosis-progression/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
       "0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker\n",
       "1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker\n",
       "2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker\n",
       "3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker\n",
       "4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ex-smoker', 'Never smoked', 'Currently smokes'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SmokingStatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tab(df):\n",
    "    vector = [(df.Age.values[0] - 30) / 30] \n",
    "    \n",
    "    if df.Sex.values[0].lower() == 'male':\n",
    "       vector.append(0)\n",
    "    else:\n",
    "       vector.append(1)\n",
    "    \n",
    "    if df.SmokingStatus.values[0] == 'Never smoked':\n",
    "        vector.extend([0,0])\n",
    "    elif df.SmokingStatus.values[0] == 'Ex-smoker':\n",
    "        vector.extend([1,1])\n",
    "    elif df.SmokingStatus.values[0] == 'Currently smokes':\n",
    "        vector.extend([0,1])\n",
    "    else:\n",
    "        vector.extend([1,0])\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c382dc29ef2c4418a1bd2e0bca3ccb85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shazz\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "A = {} \n",
    "TAB = {} \n",
    "P = [] \n",
    "for i, p in tqdm(enumerate(train.Patient.unique())):\n",
    "    sub = train.loc[train.Patient == p, :] \n",
    "    fvc = sub.FVC.values\n",
    "    weeks = sub.Weeks.values\n",
    "    c = np.vstack([weeks, np.ones(len(weeks))]).T\n",
    "    a, b = np.linalg.lstsq(c, fvc)[0]\n",
    "    \n",
    "    A[p] = a\n",
    "    TAB[p] = get_tab(sub)\n",
    "    P.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    d = pydicom.dcmread(path)\n",
    "    return cv2.resize((d.pixel_array - d.RescaleIntercept) / (d.RescaleSlope * 1000), (512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1c374a1d7c4f6aaf394ecb0ba53498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=176.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x, y = [], []\n",
    "for p in tqdm(train.Patient.unique()):\n",
    "    try:\n",
    "        ldir = os.listdir(f'osic-pulmonary-fibrosis-progression-lungs-mask/mask_noise/mask_noise/{p}/')\n",
    "        numb = [float(i[:-4]) for i in ldir]\n",
    "        for i in ldir:\n",
    "            x.append(cv2.imread(f'osic-pulmonary-fibrosis-progression-lungs-mask/mask_noise/mask_noise/{p}/{i}', 0).mean())\n",
    "            y.append(float(i[:-4]) / max(numb))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IGenerator(Sequence):\n",
    "    BAD_ID = ['ID00011637202177653955184', 'ID00052637202186188008618']\n",
    "    def __init__(self, keys, a, tab, batch_size=BATCH_SIZE):\n",
    "        self.keys = [k for k in keys if k not in self.BAD_ID]\n",
    "        self.a = a\n",
    "        self.tab = tab\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_data = {}\n",
    "        for p in train.Patient.values:\n",
    "            self.train_data[p] = os.listdir(f'C:/Users/shazz/Deep_Learning/Kaggle/input/osic-pulmonary-fibrosis-progression/train/{p}/')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = []\n",
    "        a, tab = [], [] \n",
    "        keys = np.random.choice(self.keys, size = self.batch_size)\n",
    "        for k in keys:\n",
    "            try:\n",
    "                i = np.random.choice(self.train_data[k], size=1)[0]\n",
    "                img = get_img(f'C:/Users/shazz/Deep_Learning/Kaggle/input/osic-pulmonary-fibrosis-progression/train/{k}/{i}')\n",
    "                x.append(img)\n",
    "                a.append(self.a[k])\n",
    "                tab.append(self.tab[k])\n",
    "            except:\n",
    "                print(k, i)\n",
    "       \n",
    "        x,a,tab = np.array(x), np.array(a), np.array(tab)\n",
    "        x = np.expand_dims(x, axis=-1)\n",
    "        return [x, tab] , a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_efficientnet(model, shape):\n",
    "    models_dict = {\n",
    "        'b0': efn.EfficientNetB0(input_shape=shape,weights=None,include_top=False),\n",
    "        'b1': efn.EfficientNetB1(input_shape=shape,weights=None,include_top=False),\n",
    "        'b2': efn.EfficientNetB2(input_shape=shape,weights=None,include_top=False),\n",
    "        'b3': efn.EfficientNetB3(input_shape=shape,weights=None,include_top=False),\n",
    "        'b4': efn.EfficientNetB4(input_shape=shape,weights=None,include_top=False),\n",
    "        'b5': efn.EfficientNetB5(input_shape=shape,weights=None,include_top=False),\n",
    "        'b6': efn.EfficientNetB6(input_shape=shape,weights=None,include_top=False),\n",
    "        'b7': efn.EfficientNetB7(input_shape=shape,weights=None,include_top=False)\n",
    "    }\n",
    "    return models_dict[model]\n",
    "\n",
    "def build_model(shape=(512, 512, 1), model_class=None):\n",
    "    inp = Input(shape=shape)\n",
    "    base = get_efficientnet(model_class, shape)\n",
    "    x = base(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    inp2 = Input(shape=(4,))\n",
    "    x2 = tf.keras.layers.GaussianNoise(0.2)(inp2)\n",
    "    x = Concatenate()([x, x2]) \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = Dense(1)(x)\n",
    "    model = Model([inp, inp2] , x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-c0ab98db5466>:41: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.3812 \n",
      "Epoch 00001: val_loss improved from inf to 1954.34888, saving model to effnet_30.h5\n",
      "32/32 [==============================] - 1774s 55s/step - loss: 5.3812 - val_loss: 1954.3489\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6345 \n",
      "Epoch 00002: val_loss did not improve from 1954.34888\n",
      "32/32 [==============================] - 1784s 56s/step - loss: 4.6345 - val_loss: 5249.8369\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8932 \n",
      "Epoch 00003: val_loss improved from 1954.34888 to 710.28882, saving model to effnet_30.h5\n",
      "32/32 [==============================] - 1771s 55s/step - loss: 4.8932 - val_loss: 710.2888\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4966 \n",
      "Epoch 00004: val_loss did not improve from 710.28882\n",
      "32/32 [==============================] - 1825s 57s/step - loss: 4.4966 - val_loss: 977.6589\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0817 \n",
      "Epoch 00005: val_loss improved from 710.28882 to 7.37394, saving model to effnet_30.h5\n",
      "32/32 [==============================] - 1891s 59s/step - loss: 4.0817 - val_loss: 7.3739\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2499 \n",
      "Epoch 00006: val_loss improved from 7.37394 to 4.56657, saving model to effnet_30.h5\n",
      "32/32 [==============================] - 1867s 58s/step - loss: 4.2499 - val_loss: 4.5666\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4986 \n",
      "Epoch 00007: val_loss did not improve from 4.56657\n",
      "32/32 [==============================] - 1774s 55s/step - loss: 4.4986 - val_loss: 69.6624\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7425 \n",
      "Epoch 00008: val_loss did not improve from 4.56657\n",
      "32/32 [==============================] - 1784s 56s/step - loss: 4.7425 - val_loss: 6.5541\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7478 \n",
      "Epoch 00009: val_loss did not improve from 4.56657\n",
      "32/32 [==============================] - 1703s 53s/step - loss: 4.7478 - val_loss: 102.6776\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6004 \n",
      "Epoch 00010: val_loss did not improve from 4.56657\n",
      "32/32 [==============================] - 1743s 54s/step - loss: 4.6004 - val_loss: 329.4672\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8354 \n",
      "Epoch 00011: val_loss did not improve from 4.56657\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "32/32 [==============================] - 1807s 56s/step - loss: 4.8354 - val_loss: 87.1677\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5435 \n",
      "Epoch 00012: val_loss improved from 4.56657 to 4.26197, saving model to effnet_30.h5\n",
      "32/32 [==============================] - 1773s 55s/step - loss: 4.5435 - val_loss: 4.2620\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7375 \n",
      "Epoch 00013: val_loss did not improve from 4.26197\n",
      "32/32 [==============================] - 1742s 54s/step - loss: 4.7375 - val_loss: 5.0168\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5943 \n",
      "Epoch 00014: val_loss did not improve from 4.26197\n",
      "32/32 [==============================] - 1759s 55s/step - loss: 4.5943 - val_loss: 4.3594\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5639 \n",
      "Epoch 00015: val_loss did not improve from 4.26197\n",
      "32/32 [==============================] - 1849s 58s/step - loss: 4.5639 - val_loss: 9.8696\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8843 \n",
      "Epoch 00016: val_loss improved from 4.26197 to 4.20621, saving model to effnet_30.h5\n",
      "32/32 [==============================] - 1785s 56s/step - loss: 3.8843 - val_loss: 4.2062\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5702 \n",
      "Epoch 00017: val_loss did not improve from 4.20621\n",
      "32/32 [==============================] - 1763s 55s/step - loss: 4.5702 - val_loss: 8.7670\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1195 \n",
      "Epoch 00018: val_loss improved from 4.20621 to 4.15113, saving model to effnet_30.h5\n",
      "32/32 [==============================] - 1786s 56s/step - loss: 4.1195 - val_loss: 4.1511\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4670 \n",
      "Epoch 00019: val_loss improved from 4.15113 to 3.90210, saving model to effnet_30.h5\n",
      "32/32 [==============================] - 1747s 55s/step - loss: 4.4670 - val_loss: 3.9021\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5400  \n",
      "Epoch 00020: val_loss did not improve from 3.90210\n",
      "32/32 [==============================] - 2451s 77s/step - loss: 4.5400 - val_loss: 35.5080\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6532  \n",
      "Epoch 00021: val_loss did not improve from 3.90210\n",
      "32/32 [==============================] - 3220s 101s/step - loss: 4.6532 - val_loss: 4.2788\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8186 \n",
      "Epoch 00022: val_loss did not improve from 3.90210\n",
      "32/32 [==============================] - 1946s 61s/step - loss: 3.8186 - val_loss: 4.0025\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5041  \n",
      "Epoch 00023: val_loss did not improve from 3.90210\n",
      "32/32 [==============================] - 2170s 68s/step - loss: 4.5041 - val_loss: 4.6099\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9409 \n",
      "Epoch 00024: val_loss did not improve from 3.90210\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.000750000006519258.\n",
      "32/32 [==============================] - 1916s 60s/step - loss: 4.9409 - val_loss: 4.6328\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5137 \n",
      "Epoch 00025: val_loss did not improve from 3.90210\n",
      "32/32 [==============================] - 1997s 62s/step - loss: 4.5137 - val_loss: 4.8354\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0732  \n",
      "Epoch 00026: val_loss did not improve from 3.90210\n",
      "32/32 [==============================] - 3687s 115s/step - loss: 4.0732 - val_loss: 4.4052\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5371  \n",
      "Epoch 00027: val_loss did not improve from 3.90210\n",
      "32/32 [==============================] - 2407s 75s/step - loss: 4.5371 - val_loss: 4.2188\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5873  \n",
      "Epoch 00028: val_loss did not improve from 3.90210\n",
      "32/32 [==============================] - 2015s 63s/step - loss: 4.5873 - val_loss: 4.6771\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8961  \n",
      "Epoch 00029: val_loss did not improve from 3.90210\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.000375000003259629.\n",
      "32/32 [==============================] - 1990s 62s/step - loss: 3.8961 - val_loss: 4.1667\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5636 \n",
      "Epoch 00030: val_loss did not improve from 3.90210\n",
      "32/32 [==============================] - 1981s 62s/step - loss: 4.5636 - val_loss: 4.6692\n",
      "Training done!\n"
     ]
    }
   ],
   "source": [
    "P = np.array(P)\n",
    "subs = []\n",
    "folds_history = []\n",
    "    \n",
    "er = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=1e-3,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "cpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=f'effnet_{EPOCHS}.h5',\n",
    "    monitor='val_loss', \n",
    "    verbose=1, \n",
    "    save_best_only=SAVE_BEST,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "rlp = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5,\n",
    "    patience=5, \n",
    "    verbose=1, \n",
    "    min_lr=1e-8\n",
    ")\n",
    "model = build_model(model_class=MODEL_CLASS)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss=\"mae\") \n",
    "history = model.fit_generator(IGenerator(keys=P, \n",
    "                               a = A, \n",
    "                               tab = TAB), \n",
    "                    steps_per_epoch = 32,\n",
    "                    validation_data=IGenerator(keys=P, \n",
    "                               a = A, \n",
    "                               tab = TAB),\n",
    "                    validation_steps = 16, \n",
    "                    callbacks = [cpt, rlp], \n",
    "                    epochs=EPOCHS)\n",
    "folds_history.append(history.history)\n",
    "print('Training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
