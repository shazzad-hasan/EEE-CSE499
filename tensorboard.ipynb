{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/CSE499/osic-pulmonary-fibrosis-progression/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
       "0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker\n",
       "1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker\n",
       "2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker\n",
       "3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker\n",
       "4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ex-smoker', 'Never smoked', 'Currently smokes'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SmokingStatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tab(df):\n",
    "    \"raturn an array which contains each patient normalized age, sex and smoking status\"\n",
    "    vector = [(df.Age.values[0] - 30) / 30] \n",
    "    \n",
    "    if df.Sex.values[0].lower() == 'male':\n",
    "       vector.append(0)\n",
    "    else:\n",
    "       vector.append(1)\n",
    "    \n",
    "    if df.SmokingStatus.values[0] == 'Never smoked':\n",
    "        vector.extend([0,0])\n",
    "    elif df.SmokingStatus.values[0] == 'Ex-smoker':\n",
    "        vector.extend([1,1])\n",
    "    elif df.SmokingStatus.values[0] == 'Currently smokes':\n",
    "        vector.extend([0,1])\n",
    "    else:\n",
    "        vector.extend([1,0])\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91f5e0f7f4b4603a13736f30971435c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Monir\\anaconda3\\envs\\rabbi36\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "A = {} \n",
    "TAB = {} \n",
    "P = [] \n",
    "for i, p in tqdm(enumerate(train.Patient.unique())): # i index, p patient id\n",
    "    sub = train.loc[train.Patient == p, :] # find all data (weeks, FVC, Percent, Age, Sex, SmokingStatus) of a unique patient\n",
    "    fvc = sub.FVC.values # fvc values of the patient during the follow-up\n",
    "    weeks = sub.Weeks.values # follow-up weeks\n",
    "    c = np.vstack([weeks, np.ones(len(weeks))]).T # create an array by the follow-up weeks of shape(len(weeks),2)\n",
    "    a, b = np.linalg.lstsq(c, fvc)[0] # least-square sol, a=gradient matrix, b=right hand matrix \n",
    "    \n",
    "    A[p] = a\n",
    "    TAB[p] = get_tab(sub)\n",
    "    P.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    \"read DICOM dataset and return resize images of size (512,512,1)\"\n",
    "    d = pydicom.dcmread(path) # read and parse the CT scan images (in DICOM format)\n",
    "    resized_image = cv2.resize((d.pixel_array - d.RescaleIntercept) / (d.RescaleSlope * 1000), (512,512))\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class IGenerator(Sequence):\n",
    "    BAD_ID = ['ID00011637202177653955184', 'ID00052637202186188008618']\n",
    "    def __init__(self, keys, a, tab, batch_size):\n",
    "        \"key=patient, a=gradient matrix, tab=a particular patient's data\"\n",
    "        self.keys = [k for k in keys if k not in self.BAD_ID]\n",
    "        self.a = a\n",
    "        self.tab = tab\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_data = {}\n",
    "        for p in train.Patient.values:\n",
    "            self.train_data[p] = os.listdir(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{p}/')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = []\n",
    "        a, tab = [], [] \n",
    "        keys = np.random.choice(self.keys, size = self.batch_size) # randomly chooses n=batch_size number of patients\n",
    "        for k in keys:\n",
    "            try:\n",
    "                i = np.random.choice(self.train_data[k], size=1)[0] # chooses some randomly images for kth patient\n",
    "                img = get_img(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{k}/{i}') # resizes ith image of kth patient\n",
    "                x.append(img) # append kth patient's image data in the list x\n",
    "                a.append(self.a[k]) # append kth patient's gradinet in the list a\n",
    "                tab.append(self.tab[k]) # append kth patient's tabular data in the tab list\n",
    "            except:\n",
    "                print(k, i)\n",
    "       \n",
    "        x,a,tab = np.array(x), np.array(a), np.array(tab) # convert list to array\n",
    "        x = np.expand_dims(x, axis=-1) \n",
    "        return [x, tab] , a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Activation, Flatten, Input, BatchNormalization, GlobalAveragePooling2D, GaussianNoise, \n",
    "    Add, Conv2D, AveragePooling2D, LeakyReLU, Concatenate \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "def get_efficientnet(model, shape):\n",
    "    models_dict = {\n",
    "        'b0': efn.EfficientNetB0(input_shape=shape,weights=None,include_top=False),\n",
    "        'b1': efn.EfficientNetB1(input_shape=shape,weights=None,include_top=False),\n",
    "        'b2': efn.EfficientNetB2(input_shape=shape,weights=None,include_top=False),\n",
    "        'b3': efn.EfficientNetB3(input_shape=shape,weights=None,include_top=False),\n",
    "        'b4': efn.EfficientNetB4(input_shape=shape,weights=None,include_top=False),\n",
    "        'b5': efn.EfficientNetB5(input_shape=shape,weights=None,include_top=False),\n",
    "        'b6': efn.EfficientNetB6(input_shape=shape,weights=None,include_top=False),\n",
    "        'b7': efn.EfficientNetB7(input_shape=shape,weights=None,include_top=False)\n",
    "    }\n",
    "    return models_dict[model]\n",
    "\n",
    "def build_model(shape, model_class=None):\n",
    "    inp = Input(shape=shape)\n",
    "    base = get_efficientnet(model_class, shape)\n",
    "    x = base(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    inp2 = Input(shape=(4,)) # indicates that the expected input will be batches of 4-dimensional vectors\n",
    "    x2 = GaussianNoise(0.2)(inp2) # to mitigate overfitting\n",
    "    x = Concatenate()([x, x2]) \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = Dense(1)(x)\n",
    "    model = Model([inp, inp2] , x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "EPOCHS = 80\n",
    "LR = 0.001\n",
    "SAVE_BEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array(P)\n",
    "subs = []\n",
    "folds_history = []\n",
    "\n",
    "\n",
    "#er = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",min_delta=1e-3,patience=15,verbose=1,mode=\"auto\",baseline=None,\n",
    "#      restore_best_weights=True,) #Stop training when a monitored metric has stopped improving.\n",
    "\n",
    "\n",
    "#cpt = tf.keras.callbacks.ModelCheckpoint(filepath=f'C:/Users/Monir/Documents/CSE499/models/EfficientNet/{MODEL_CLASS}_{EPOCHS}_epochs.h5',monitor='val_loss',verbose=1, \n",
    "#    save_best_only=SAVE_BEST,mode='auto') #to save model or weights in a checkpoint file at lowest validation loss\n",
    "\n",
    "#rlp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=5, verbose=1, min_lr=1e-8) \n",
    "     #Reduce learning rate when a metric has stopped improving.\n",
    "     # if improvement stops, after 5 epochs learning rate will be reduced\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model_class=None, shape=(512, 512, 1)):\n",
    "    print(model_class)\n",
    "    \n",
    "    inp = Input(shape=shape)\n",
    "    base = get_efficientnet(model_class, shape)\n",
    "    x = base(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    inp2 = Input(shape=(4,)) # indicates that the expected input will be batches of 4-dimensional vectors\n",
    "    x2 = GaussianNoise(0.2)(inp2) # to mitigate overfitting\n",
    "    x = Concatenate()([x, x2]) \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = Dense(1)(x)\n",
    "    model = Model([inp, inp2] , x)\n",
    "    \n",
    "    \n",
    "    #model = build_model(model_class, shape)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss=\"mae\")\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(IGenerator(keys=P, a = A, tab = TAB, batch_size=BATCH_SIZE), \n",
    "                    steps_per_epoch = 32,\n",
    "                    validation_data=IGenerator(keys=P, a = A, tab = TAB, batch_size=BATCH_SIZE),\n",
    "                    validation_steps = 32, \n",
    "#                    callbacks = [cpt, rlp], \n",
    "                    epochs=EPOCHS)\n",
    "    folds_history.append(history.history)\n",
    "    print('Training Complete!!!')\n",
    "  \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-b0 (Model)         (None, 16, 16, 1280) 4048988     input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1280)         0           efficientnet-b0[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNoise (None, 4)            0           input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1284)         0           global_average_pooling2d_1[0][0] \n",
      "                                                                 gaussian_noise_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1284)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1285        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,050,273\n",
      "Trainable params: 4,008,257\n",
      "Non-trainable params: 42,016\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/80\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 5.6453 - val_loss: 6.9201\n",
      "Epoch 2/80\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 5.2554 - val_loss: 5.3566\n",
      "Epoch 3/80\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 4.0561 - val_loss: 3.8524\n",
      "Epoch 4/80\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 4.1838 - val_loss: 4.7887\n",
      "Epoch 5/80\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 4.3578 - val_loss: 22.3365\n",
      "Epoch 6/80\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 5.0000 - val_loss: 72.8993\n",
      "Epoch 7/80\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 5.5050 - val_loss: 172.6138\n",
      "Epoch 8/80\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 3.4395 - val_loss: 295.2505\n",
      "Epoch 9/80\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 4.4744 - val_loss: 4.1980\n",
      "Epoch 10/80\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 5.1527 - val_loss: 4.5586\n",
      "Epoch 11/80\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 4.7450 - val_loss: 6.5020\n",
      "Epoch 12/80\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 4.8078 - val_loss: 20.3053\n",
      "Epoch 13/80\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 5.6570 - val_loss: 55.8676\n",
      "Epoch 14/80\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 3.8968 - val_loss: 24.6287\n",
      "Epoch 15/80\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 4.2733 - val_loss: 55.6383\n",
      "Epoch 16/80\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 5.3084 - val_loss: 226.3123\n",
      "Epoch 17/80\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 4.3380 - val_loss: 61.5999\n",
      "Epoch 18/80\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 3.9065 - val_loss: 45.4287\n",
      "Epoch 19/80\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 5.0470 - val_loss: 12.6854\n",
      "Epoch 20/80\n",
      "32/32 [==============================] - 3s 108ms/step - loss: 4.4260 - val_loss: 10.2546\n",
      "Epoch 21/80\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 3.8855 - val_loss: 21.0657\n",
      "Epoch 22/80\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 3.9453 - val_loss: 111.9448\n",
      "Epoch 23/80\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 4.8575 - val_loss: 48.0383\n",
      "Epoch 24/80\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 3.9469 - val_loss: 29.1342\n",
      "Epoch 25/80\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 4.3389 - val_loss: 24.3108\n",
      "Epoch 26/80\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 4.2366 - val_loss: 44.8380\n",
      "Epoch 27/80\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 3.2884 - val_loss: 5.2531\n",
      "Epoch 28/80\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 5.2370 - val_loss: 48.3432\n",
      "Epoch 29/80\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 4.2580 - val_loss: 29.4102\n",
      "Epoch 30/80\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 4.1728 - val_loss: 46.5567\n",
      "Epoch 31/80\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 5.4031 - val_loss: 44.4339\n",
      "Epoch 32/80\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 5.0217 - val_loss: 47.5524\n",
      "Epoch 33/80\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 4.3119 - val_loss: 26.6053\n",
      "Epoch 34/80\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 3.4177 - val_loss: 10.3505\n",
      "Epoch 35/80\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 4.7305 - val_loss: 4.8821\n",
      "Epoch 36/80\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 4.4165 - val_loss: 42.6704\n",
      "Epoch 37/80\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 4.5103 - val_loss: 34.1762\n",
      "Epoch 38/80\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 5.2626 - val_loss: 17.6655\n",
      "Epoch 39/80\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 4.9191 - val_loss: 114.1584\n",
      "Epoch 40/80\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 4.3143 - val_loss: 43.2053\n",
      "Epoch 41/80\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 4.6839 - val_loss: 3.8562\n",
      "Epoch 42/80\n",
      "32/32 [==============================] - 3s 108ms/step - loss: 4.6739 - val_loss: 4.3892\n",
      "Epoch 43/80\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 4.4710 - val_loss: 3.3526\n",
      "Epoch 44/80\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 4.0556 - val_loss: 3.8531\n",
      "Epoch 45/80\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 3.1968 - val_loss: 4.4855\n",
      "Epoch 46/80\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 4.6910 - val_loss: 4.7291\n",
      "Epoch 47/80\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 4.3440 - val_loss: 3.4771\n",
      "Epoch 48/80\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 3.7280 - val_loss: 4.5022\n",
      "Epoch 49/80\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 4.9157 - val_loss: 4.8585\n",
      "Epoch 50/80\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 4.9426 - val_loss: 4.6610\n",
      "Epoch 51/80\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 4.9730 - val_loss: 3.9771\n",
      "Epoch 52/80\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 4.6468 - val_loss: 5.2413\n",
      "Epoch 53/80\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 4.5419 - val_loss: 3.2448\n",
      "Epoch 54/80\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 4.4150 - val_loss: 4.6962\n",
      "Epoch 55/80\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 4.1811 - val_loss: 4.3588\n",
      "Epoch 56/80\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 3.8963 - val_loss: 3.6063\n",
      "Epoch 57/80\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 4.0911 - val_loss: 4.5133\n",
      "Epoch 58/80\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 5.1790 - val_loss: 3.5107\n",
      "Epoch 59/80\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 5.2737 - val_loss: 4.4590\n",
      "Epoch 60/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 110ms/step - loss: 4.5674 - val_loss: 3.6198\n",
      "Epoch 61/80\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 3.4729 - val_loss: 4.0285\n",
      "Epoch 62/80\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 4.1879 - val_loss: 3.8661\n",
      "Epoch 63/80\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 3.5523 - val_loss: 4.1168\n",
      "Epoch 64/80\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 4.1491 - val_loss: 4.5082\n",
      "Epoch 65/80\n",
      "32/32 [==============================] - 4s 112ms/step - loss: 4.7612 - val_loss: 4.4689\n",
      "Epoch 66/80\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 4.2249 - val_loss: 3.6331\n",
      "Epoch 67/80\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 4.1576 - val_loss: 4.6911\n",
      "Epoch 68/80\n",
      "32/32 [==============================] - 3s 109ms/step - loss: 4.8467 - val_loss: 3.5275\n",
      "Epoch 69/80\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 4.2797 - val_loss: 3.9194\n",
      "Epoch 70/80\n",
      "32/32 [==============================] - 4s 111ms/step - loss: 3.5622 - val_loss: 4.5593\n",
      "Epoch 71/80\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 4.4304 - val_loss: 5.3123\n",
      "Epoch 72/80\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 3.7799 - val_loss: 3.8714\n",
      "Epoch 73/80\n",
      "32/32 [==============================] - 4s 121ms/step - loss: 4.2732 - val_loss: 4.3828\n",
      "Epoch 74/80\n",
      "32/32 [==============================] - 4s 133ms/step - loss: 3.8716 - val_loss: 4.6153\n",
      "Epoch 75/80\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 3.5692 - val_loss: 3.8693\n",
      "Epoch 76/80\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 3.7475 - val_loss: 4.9199\n",
      "Epoch 77/80\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 5.0800 - val_loss: 3.3560\n",
      "Epoch 78/80\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 4.5015 - val_loss: 4.6238\n",
      "Epoch 79/80\n",
      "32/32 [==============================] - 4s 117ms/step - loss: 4.9978 - val_loss: 4.7159\n",
      "Epoch 80/80\n",
      "32/32 [==============================] - 4s 113ms/step - loss: 2.8316 - val_loss: 5.2566\n",
      "Training Complete!!!\n"
     ]
    }
   ],
   "source": [
    "MODEL_CLASS = 'b0'\n",
    "\n",
    "histories[MODEL_CLASS] = train_and_evaluate_model(model_class=MODEL_CLASS, shape=(512, 512, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['b1', 'b0'])\n"
     ]
    }
   ],
   "source": [
    "print(histories.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model History "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Training Results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
