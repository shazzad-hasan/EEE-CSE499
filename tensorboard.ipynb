{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-0cddaa2dbc5f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-0cddaa2dbc5f>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    rm -rf ./logs/\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/CSE499/osic-pulmonary-fibrosis-progression/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
       "0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker\n",
       "1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker\n",
       "2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker\n",
       "3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker\n",
       "4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ex-smoker', 'Never smoked', 'Currently smokes'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SmokingStatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tab(df):\n",
    "    \"raturn an array which contains each patient normalized age, sex and smoking status\"\n",
    "    vector = [(df.Age.values[0] - 30) / 30] \n",
    "    \n",
    "    if df.Sex.values[0].lower() == 'male':\n",
    "       vector.append(0)\n",
    "    else:\n",
    "       vector.append(1)\n",
    "    \n",
    "    if df.SmokingStatus.values[0] == 'Never smoked':\n",
    "        vector.extend([0,0])\n",
    "    elif df.SmokingStatus.values[0] == 'Ex-smoker':\n",
    "        vector.extend([1,1])\n",
    "    elif df.SmokingStatus.values[0] == 'Currently smokes':\n",
    "        vector.extend([0,1])\n",
    "    else:\n",
    "        vector.extend([1,0])\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ce43b3b0f34d0faa572236c9bb3c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Monir\\anaconda3\\envs\\rabbi36\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "A = {} \n",
    "TAB = {} \n",
    "P = [] \n",
    "for i, p in tqdm(enumerate(train.Patient.unique())): # i index, p patient id\n",
    "    sub = train.loc[train.Patient == p, :] # find all data (weeks, FVC, Percent, Age, Sex, SmokingStatus) of a unique patient\n",
    "    fvc = sub.FVC.values # fvc values of the patient during the follow-up\n",
    "    weeks = sub.Weeks.values # follow-up weeks\n",
    "    c = np.vstack([weeks, np.ones(len(weeks))]).T # create an array by the follow-up weeks of shape(len(weeks),2)\n",
    "    a, b = np.linalg.lstsq(c, fvc)[0] # least-square sol, a=gradient matrix, b=right hand matrix \n",
    "    \n",
    "    A[p] = a\n",
    "    TAB[p] = get_tab(sub)\n",
    "    P.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    \"read DICOM dataset and return resize images of size (512,512,1)\"\n",
    "    d = pydicom.dcmread(path) # read and parse the CT scan images (in DICOM format)\n",
    "    resized_image = cv2.resize((d.pixel_array - d.RescaleIntercept) / (d.RescaleSlope * 1000), (512,512))\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class IGenerator(Sequence):\n",
    "    BAD_ID = ['ID00011637202177653955184', 'ID00052637202186188008618']\n",
    "    def __init__(self, keys, a, tab, batch_size):\n",
    "        \"key=patient, a=gradient matrix, tab=a particular patient's data\"\n",
    "        self.keys = [k for k in keys if k not in self.BAD_ID]\n",
    "        self.a = a\n",
    "        self.tab = tab\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_data = {}\n",
    "        for p in train.Patient.values:\n",
    "            self.train_data[p] = os.listdir(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{p}/')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = []\n",
    "        a, tab = [], [] \n",
    "        keys = np.random.choice(self.keys, size = self.batch_size) # randomly chooses n=batch_size number of patients\n",
    "        for k in keys:\n",
    "            try:\n",
    "                i = np.random.choice(self.train_data[k], size=1)[0] # chooses some randomly images for kth patient\n",
    "                img = get_img(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{k}/{i}') # resizes ith image of kth patient\n",
    "                x.append(img) # append kth patient's image data in the list x\n",
    "                a.append(self.a[k]) # append kth patient's gradinet in the list a\n",
    "                tab.append(self.tab[k]) # append kth patient's tabular data in the tab list\n",
    "            except:\n",
    "                print(k, i)\n",
    "       \n",
    "        x,a,tab = np.array(x), np.array(a), np.array(tab) # convert list to array\n",
    "        x = np.expand_dims(x, axis=-1) \n",
    "        return [x, tab] , a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Activation, Flatten, Input, BatchNormalization, GlobalAveragePooling2D, GaussianNoise, \n",
    "    Add, Conv2D, AveragePooling2D, LeakyReLU, Concatenate \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import efficientnet.tfkeras as efn\n",
    "from keras.applications import resnet50, inception_v3\n",
    "\n",
    "def get_model(model, shape):\n",
    "    models_dict = {\n",
    "        'b0': efn.EfficientNetB0(input_shape=shape,weights=None,include_top=False),\n",
    "        'b1': efn.EfficientNetB1(input_shape=shape,weights=None,include_top=False),\n",
    "        'b2': efn.EfficientNetB2(input_shape=shape,weights=None,include_top=False),\n",
    "        'b3': efn.EfficientNetB3(input_shape=shape,weights=None,include_top=False),\n",
    "        'b4': efn.EfficientNetB4(input_shape=shape,weights=None,include_top=False),\n",
    "        'b5': efn.EfficientNetB5(input_shape=shape,weights=None,include_top=False),\n",
    "        'b6': efn.EfficientNetB6(input_shape=shape,weights=None,include_top=False),\n",
    "        'b7': efn.EfficientNetB7(input_shape=shape,weights=None,include_top=False),\n",
    "        'RNet50': resnet50.ResNet50(input_shape=shape,weights=None,include_top=False),\n",
    "        'InceptionV3': inception_v3.InceptionV3(input_shape=shape,weights=None,include_top=False)    \n",
    "    }\n",
    "    return models_dict[model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "EPOCHS = 20\n",
    "LR = 0.001\n",
    "SAVE_BEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array(P)\n",
    "subs = []\n",
    "folds_history = []\n",
    "\n",
    "\n",
    "er = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",min_delta=1e-3,patience=15,verbose=1,mode=\"auto\",baseline=None,\n",
    "      restore_best_weights=True,) #Stop training when a monitored metric has stopped improving.\n",
    "\n",
    "\n",
    "cpt = tf.keras.callbacks.ModelCheckpoint(filepath=f'C:/Users/Monir/Documents/CSE499/models/EfficientNet/{MODEL_CLASS}_{EPOCHS}_epochs.h5',monitor='val_loss',verbose=1, \n",
    "    save_best_only=SAVE_BEST,mode='auto') #to save model or weights in a checkpoint file at lowest validation loss\n",
    "\n",
    "rlp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=5, verbose=1, min_lr=1e-8) \n",
    "     #Reduce learning rate when a metric has stopped improving.\n",
    "     # if improvement stops, after 5 epochs learning rate will be reduced\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model_class=None, shape=(512, 512, 1)):\n",
    "    inp = Input(shape=shape)\n",
    "    base = get_model(model_class, shape)\n",
    "    x = base(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    inp2 = Input(shape=(4,)) # indicates that the expected input will be batches of 4-dimensional vectors\n",
    "    x2 = GaussianNoise(0.2)(inp2) # to mitigate overfitting\n",
    "    x = Concatenate()([x, x2]) \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = Dense(1)(x)\n",
    "    model = Model([inp, inp2] , x)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss=\"mae\")\n",
    "    model.summary()\n",
    "    \n",
    "    logdir = os.path.join(\"logs/fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    td_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "    history = model.fit(IGenerator(keys=P, a = A, tab = TAB, batch_size=BATCH_SIZE), \n",
    "                    steps_per_epoch = 32,\n",
    "                    validation_data=IGenerator(keys=P, a = A, tab = TAB, batch_size=BATCH_SIZE),\n",
    "                    validation_steps = 32, \n",
    "                    callbacks = [td_callback,rlp,er,cpt], \n",
    "                    epochs=EPOCHS)\n",
    "    folds_history.append(history.history)\n",
    "    print('Training Complete!!!')\n",
    "  \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Monir\\anaconda3\\envs\\rabbi36\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-b1 (Model)         (None, 16, 16, 1280) 6574656     input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1280)         0           efficientnet-b1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise_2 (GaussianNoise (None, 4)            0           input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1284)         0           global_average_pooling2d_2[0][0] \n",
      "                                                                 gaussian_noise_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1284)         0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            1285        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,575,941\n",
      "Trainable params: 6,513,893\n",
      "Non-trainable params: 62,048\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      " 2/32 [>.............................] - ETA: 19s - loss: 5.1685WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.578175). Check your callbacks.\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9989\n",
      "Epoch 00001: val_loss improved from inf to 5.20981, saving model to C:/Users/Monir/Documents/CSE499/models/EfficientNet/b1_20_epochs.h5\n",
      "32/32 [==============================] - 11s 334ms/step - loss: 4.9989 - val_loss: 5.2098 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4735\n",
      "Epoch 00002: val_loss improved from 5.20981 to 3.71157, saving model to C:/Users/Monir/Documents/CSE499/models/EfficientNet/b1_20_epochs.h5\n",
      "32/32 [==============================] - 12s 383ms/step - loss: 4.4735 - val_loss: 3.7116 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0657\n",
      "Epoch 00003: val_loss did not improve from 3.71157\n",
      "32/32 [==============================] - 7s 215ms/step - loss: 5.0657 - val_loss: 58.3948 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.4472\n",
      "Epoch 00004: val_loss did not improve from 3.71157\n",
      "32/32 [==============================] - 7s 223ms/step - loss: 5.4472 - val_loss: 12.4722 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8782\n",
      "Epoch 00005: val_loss did not improve from 3.71157\n",
      "32/32 [==============================] - 7s 216ms/step - loss: 4.8782 - val_loss: 23.6199 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9572\n",
      "Epoch 00006: val_loss did not improve from 3.71157\n",
      "32/32 [==============================] - 7s 223ms/step - loss: 3.9572 - val_loss: 20.9343 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5824\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.71157\n",
      "32/32 [==============================] - 7s 214ms/step - loss: 3.5824 - val_loss: 6.9756 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.3581\n",
      "Epoch 00008: val_loss did not improve from 3.71157\n",
      "32/32 [==============================] - 7s 209ms/step - loss: 5.3581 - val_loss: 13.3879 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.5429\n",
      "Epoch 00009: val_loss did not improve from 3.71157\n",
      "32/32 [==============================] - 7s 211ms/step - loss: 5.5429 - val_loss: 58.3192 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.2895\n",
      "Epoch 00010: val_loss did not improve from 3.71157\n",
      "32/32 [==============================] - 7s 215ms/step - loss: 5.2895 - val_loss: 29.2665 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1252\n",
      "Epoch 00011: val_loss did not improve from 3.71157\n",
      "32/32 [==============================] - 7s 209ms/step - loss: 4.1252 - val_loss: 7.2493 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3875\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.71157\n",
      "32/32 [==============================] - 7s 210ms/step - loss: 4.3875 - val_loss: 129.6350 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6272\n",
      "Epoch 00013: val_loss did not improve from 3.71157\n",
      "32/32 [==============================] - 7s 216ms/step - loss: 4.6272 - val_loss: 38.0942 - lr: 2.5000e-04\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8639\n",
      "Epoch 00014: val_loss did not improve from 3.71157\n",
      "32/32 [==============================] - 7s 217ms/step - loss: 4.8639 - val_loss: 18.8190 - lr: 2.5000e-04\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2574\n",
      "Epoch 00015: val_loss did not improve from 3.71157\n",
      "32/32 [==============================] - 7s 217ms/step - loss: 4.2574 - val_loss: 10.3895 - lr: 2.5000e-04\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1196\n",
      "Epoch 00016: val_loss did not improve from 3.71157\n",
      "32/32 [==============================] - 7s 212ms/step - loss: 4.1196 - val_loss: 18.0043 - lr: 2.5000e-04\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6194\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.71157\n",
      "32/32 [==============================] - 7s 217ms/step - loss: 4.6194 - val_loss: 26.7179 - lr: 2.5000e-04\n",
      "Epoch 00017: early stopping\n",
      "Training Complete!!!\n"
     ]
    }
   ],
   "source": [
    "MODEL_CLASS = 'b1'\n",
    "import datetime, os\n",
    "histories[MODEL_CLASS] = train_and_evaluate_model(model_class=MODEL_CLASS, shape=(512, 512, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['b1'])\n"
     ]
    }
   ],
   "source": [
    "print(histories.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model History "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9032), started 0:16:23 ago. (Use '!kill 9032' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-304456701f6d5a43\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-304456701f6d5a43\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
