{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/CSE499/osic-pulmonary-fibrosis-progression/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
       "0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker\n",
       "1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker\n",
       "2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker\n",
       "3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker\n",
       "4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ex-smoker', 'Never smoked', 'Currently smokes'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SmokingStatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tab(df):\n",
    "    \"raturn an array which contains each patient normalized age, sex and smoking status\"\n",
    "    vector = [(df.Age.values[0] - 30) / 30] \n",
    "    \n",
    "    if df.Sex.values[0].lower() == 'male':\n",
    "       vector.append(0)\n",
    "    else:\n",
    "       vector.append(1)\n",
    "    \n",
    "    if df.SmokingStatus.values[0] == 'Never smoked':\n",
    "        vector.extend([0,0])\n",
    "    elif df.SmokingStatus.values[0] == 'Ex-smoker':\n",
    "        vector.extend([1,1])\n",
    "    elif df.SmokingStatus.values[0] == 'Currently smokes':\n",
    "        vector.extend([0,1])\n",
    "    else:\n",
    "        vector.extend([1,0])\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d418d7c4db745b0a27cdceed55fcaf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Monir\\anaconda3\\envs\\rabbi36\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "A = {} \n",
    "TAB = {} \n",
    "P = [] \n",
    "for i, p in tqdm(enumerate(train.Patient.unique())): # i index, p patient id\n",
    "    sub = train.loc[train.Patient == p, :] # find all data (weeks, FVC, Percent, Age, Sex, SmokingStatus) of a unique patient\n",
    "    fvc = sub.FVC.values # fvc values of the patient during the follow-up\n",
    "    weeks = sub.Weeks.values # follow-up weeks\n",
    "    c = np.vstack([weeks, np.ones(len(weeks))]).T # create an array by the follow-up weeks of shape(len(weeks),2)\n",
    "    a, b = np.linalg.lstsq(c, fvc)[0] # least-square sol, a=gradient matrix, b=right hand matrix \n",
    "    \n",
    "    A[p] = a\n",
    "    TAB[p] = get_tab(sub)\n",
    "    P.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    \"read DICOM dataset and return resize images of size (512,512,1)\"\n",
    "    d = pydicom.dcmread(path) # read and parse the CT scan images (in DICOM format)\n",
    "    resized_image = cv2.resize((d.pixel_array - d.RescaleIntercept) / (d.RescaleSlope * 1000), (512,512))\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class IGenerator(Sequence):\n",
    "    BAD_ID = ['ID00011637202177653955184', 'ID00052637202186188008618']\n",
    "    def __init__(self, keys, a, tab, batch_size):\n",
    "        \"key=patient, a=gradient matrix, tab=a particular patient's data\"\n",
    "        self.keys = [k for k in keys if k not in self.BAD_ID]\n",
    "        self.a = a\n",
    "        self.tab = tab\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_data = {}\n",
    "        for p in train.Patient.values:\n",
    "            self.train_data[p] = os.listdir(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{p}/')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = []\n",
    "        a, tab = [], [] \n",
    "        keys = np.random.choice(self.keys, size = self.batch_size) # randomly chooses n=batch_size number of patients\n",
    "        for k in keys:\n",
    "            try:\n",
    "                i = np.random.choice(self.train_data[k], size=1)[0] # chooses some randomly images for kth patient\n",
    "                img = get_img(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{k}/{i}') # resizes ith image of kth patient\n",
    "                x.append(img) # append kth patient's image data in the list x\n",
    "                a.append(self.a[k]) # append kth patient's gradinet in the list a\n",
    "                tab.append(self.tab[k]) # append kth patient's tabular data in the tab list\n",
    "            except:\n",
    "                print(k, i)\n",
    "       \n",
    "        x,a,tab = np.array(x), np.array(a), np.array(tab) # convert list to array\n",
    "        x = np.expand_dims(x, axis=-1) \n",
    "        return [x, tab] , a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Activation, Flatten, Input, BatchNormalization, GlobalAveragePooling2D, GaussianNoise, \n",
    "    Add, Conv2D, AveragePooling2D, LeakyReLU, Concatenate \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "def get_efficientnet(model, shape):\n",
    "    models_dict = {\n",
    "        'b0': efn.EfficientNetB0(input_shape=shape,weights=None,include_top=False),\n",
    "        'b1': efn.EfficientNetB1(input_shape=shape,weights=None,include_top=False),\n",
    "        'b2': efn.EfficientNetB2(input_shape=shape,weights=None,include_top=False),\n",
    "        'b3': efn.EfficientNetB3(input_shape=shape,weights=None,include_top=False),\n",
    "        'b4': efn.EfficientNetB4(input_shape=shape,weights=None,include_top=False),\n",
    "        'b5': efn.EfficientNetB5(input_shape=shape,weights=None,include_top=False),\n",
    "        'b6': efn.EfficientNetB6(input_shape=shape,weights=None,include_top=False),\n",
    "        'b7': efn.EfficientNetB7(input_shape=shape,weights=None,include_top=False)\n",
    "    }\n",
    "    return models_dict[model]\n",
    "\n",
    "def build_model(shape=(512, 512, 1), model_class=None):\n",
    "    inp = Input(shape=shape)\n",
    "    base = get_efficientnet(model_class, shape)\n",
    "    x = base(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    inp2 = Input(shape=(4,)) # indicates that the expected input will be batches of 4-dimensional vectors\n",
    "    x2 = GaussianNoise(0.2)(inp2) # to mitigate overfitting\n",
    "    x = Concatenate()([x, x2]) \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = Dense(1)(x)\n",
    "    model = Model([inp, inp2] , x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-b6 (Model)         (None, 16, 16, 2304) 40959128    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2304)         0           efficientnet-b6[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 4)            0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2308)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2308)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2309        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 40,961,437\n",
      "Trainable params: 40,737,005\n",
      "Non-trainable params: 224,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MODEL_CLASS = 'b6'\n",
    "base_model = build_model(shape=(512, 512, 1), model_class=MODEL_CLASS)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 80\n",
    "LR = 0.001\n",
    "SAVE_BEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.5133\n",
      "Epoch 00001: val_loss improved from inf to 14.07072, saving model to C:/Users/Monir/Documents/CSE499/models/EfficientNet/b6_80_epochs.h5\n",
      "32/32 [==============================] - 13s 413ms/step - loss: 5.5133 - val_loss: 14.0707 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2448\n",
      "Epoch 00002: val_loss improved from 14.07072 to 5.49380, saving model to C:/Users/Monir/Documents/CSE499/models/EfficientNet/b6_80_epochs.h5\n",
      "32/32 [==============================] - 20s 620ms/step - loss: 4.2448 - val_loss: 5.4938 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5110\n",
      "Epoch 00003: val_loss did not improve from 5.49380\n",
      "32/32 [==============================] - 8s 247ms/step - loss: 3.5110 - val_loss: 27736.9629 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7313\n",
      "Epoch 00004: val_loss did not improve from 5.49380\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 4.7313 - val_loss: 155.4260 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1774\n",
      "Epoch 00005: val_loss did not improve from 5.49380\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 4.1774 - val_loss: 646.1752 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9810\n",
      "Epoch 00006: val_loss did not improve from 5.49380\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 4.9810 - val_loss: 515.4234 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9674\n",
      "Epoch 00007: val_loss improved from 5.49380 to 4.73173, saving model to C:/Users/Monir/Documents/CSE499/models/EfficientNet/b6_80_epochs.h5\n",
      "32/32 [==============================] - 20s 619ms/step - loss: 3.9674 - val_loss: 4.7317 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0429\n",
      "Epoch 00008: val_loss did not improve from 4.73173\n",
      "32/32 [==============================] - 8s 262ms/step - loss: 4.0429 - val_loss: 2578.1445 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3530\n",
      "Epoch 00009: val_loss did not improve from 4.73173\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 4.3530 - val_loss: 10271.2236 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.5462\n",
      "Epoch 00010: val_loss did not improve from 4.73173\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 5.5462 - val_loss: 484.5753 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3911\n",
      "Epoch 00011: val_loss did not improve from 4.73173\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 4.3911 - val_loss: 7546.1172 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3198\n",
      "Epoch 00012: val_loss did not improve from 4.73173\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 4.3198 - val_loss: 36180.9336 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5636\n",
      "Epoch 00013: val_loss did not improve from 4.73173\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 4.5636 - val_loss: 7364.0391 - lr: 5.0000e-04\n",
      "Epoch 14/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8237\n",
      "Epoch 00014: val_loss did not improve from 4.73173\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 4.8237 - val_loss: 4059.7629 - lr: 5.0000e-04\n",
      "Epoch 15/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6311\n",
      "Epoch 00015: val_loss did not improve from 4.73173\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 3.6311 - val_loss: 1042.4486 - lr: 5.0000e-04\n",
      "Epoch 16/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.1716\n",
      "Epoch 00016: val_loss did not improve from 4.73173\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 3.1716 - val_loss: 789.4431 - lr: 5.0000e-04\n",
      "Epoch 17/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5484\n",
      "Epoch 00017: val_loss did not improve from 4.73173\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 4.5484 - val_loss: 514.8509 - lr: 5.0000e-04\n",
      "Epoch 18/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0682\n",
      "Epoch 00018: val_loss did not improve from 4.73173\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 5.0682 - val_loss: 434.6039 - lr: 2.5000e-04\n",
      "Epoch 19/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5218\n",
      "Epoch 00019: val_loss did not improve from 4.73173\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 3.5218 - val_loss: 218.2724 - lr: 2.5000e-04\n",
      "Epoch 20/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2811\n",
      "Epoch 00020: val_loss did not improve from 4.73173\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 4.2811 - val_loss: 5.7300 - lr: 2.5000e-04\n",
      "Epoch 21/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7916\n",
      "Epoch 00021: val_loss did not improve from 4.73173\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 3.7916 - val_loss: 5.9380 - lr: 2.5000e-04\n",
      "Epoch 22/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2052\n",
      "Epoch 00022: val_loss did not improve from 4.73173\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 4.2052 - val_loss: 5.7687 - lr: 2.5000e-04\n",
      "Epoch 23/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0381\n",
      "Epoch 00023: val_loss improved from 4.73173 to 3.93055, saving model to C:/Users/Monir/Documents/CSE499/models/EfficientNet/b6_80_epochs.h5\n",
      "32/32 [==============================] - 19s 602ms/step - loss: 5.0381 - val_loss: 3.9306 - lr: 1.2500e-04\n",
      "Epoch 24/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0992\n",
      "Epoch 00024: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 5.0992 - val_loss: 6.2423 - lr: 1.2500e-04\n",
      "Epoch 25/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7649\n",
      "Epoch 00025: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 3.7649 - val_loss: 4.9751 - lr: 1.2500e-04\n",
      "Epoch 26/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3700\n",
      "Epoch 00026: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 4.3700 - val_loss: 15.3654 - lr: 1.2500e-04\n",
      "Epoch 27/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4861\n",
      "Epoch 00027: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 3.4861 - val_loss: 9.0046 - lr: 1.2500e-04\n",
      "Epoch 28/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6895\n",
      "Epoch 00028: val_loss did not improve from 3.93055\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 3.6895 - val_loss: 4.1688 - lr: 1.2500e-04\n",
      "Epoch 29/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5508\n",
      "Epoch 00029: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 246ms/step - loss: 4.5508 - val_loss: 6.4051 - lr: 6.2500e-05\n",
      "Epoch 30/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.7781\n",
      "Epoch 00030: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 5.7781 - val_loss: 9.3551 - lr: 6.2500e-05\n",
      "Epoch 31/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3812\n",
      "Epoch 00031: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 3.3812 - val_loss: 7.3275 - lr: 6.2500e-05\n",
      "Epoch 32/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6278\n",
      "Epoch 00032: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 4.6278 - val_loss: 20.3922 - lr: 6.2500e-05\n",
      "Epoch 33/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 4.3496\n",
      "Epoch 00033: val_loss did not improve from 3.93055\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 4.3496 - val_loss: 14.8788 - lr: 6.2500e-05\n",
      "Epoch 34/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.1939\n",
      "Epoch 00034: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 3.1939 - val_loss: 11.7721 - lr: 3.1250e-05\n",
      "Epoch 35/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3537\n",
      "Epoch 00035: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 4.3537 - val_loss: 18.9316 - lr: 3.1250e-05\n",
      "Epoch 36/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7898\n",
      "Epoch 00036: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 4.7898 - val_loss: 12.8444 - lr: 3.1250e-05\n",
      "Epoch 37/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3136\n",
      "Epoch 00037: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 4.3136 - val_loss: 9.4770 - lr: 3.1250e-05\n",
      "Epoch 38/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2694\n",
      "Epoch 00038: val_loss did not improve from 3.93055\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "32/32 [==============================] - 8s 246ms/step - loss: 4.2694 - val_loss: 14.3206 - lr: 3.1250e-05\n",
      "Epoch 39/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9236\n",
      "Epoch 00039: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 3.9236 - val_loss: 8.7778 - lr: 1.5625e-05\n",
      "Epoch 40/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1107\n",
      "Epoch 00040: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 4.1107 - val_loss: 12.8197 - lr: 1.5625e-05\n",
      "Epoch 41/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0926\n",
      "Epoch 00041: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 4.0926 - val_loss: 13.9127 - lr: 1.5625e-05\n",
      "Epoch 42/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8992\n",
      "Epoch 00042: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 4.8992 - val_loss: 7.1926 - lr: 1.5625e-05\n",
      "Epoch 43/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0343\n",
      "Epoch 00043: val_loss did not improve from 3.93055\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 4.0343 - val_loss: 8.5141 - lr: 1.5625e-05\n",
      "Epoch 44/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.2704\n",
      "Epoch 00044: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 5.2704 - val_loss: 10.6234 - lr: 7.8125e-06\n",
      "Epoch 45/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0273\n",
      "Epoch 00045: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 247ms/step - loss: 4.0273 - val_loss: 10.5593 - lr: 7.8125e-06\n",
      "Epoch 46/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.8857\n",
      "Epoch 00046: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 244ms/step - loss: 2.8857 - val_loss: 16.1878 - lr: 7.8125e-06\n",
      "Epoch 47/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0810- ETA: 2s - l\n",
      "Epoch 00047: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 5.0810 - val_loss: 10.7079 - lr: 7.8125e-06\n",
      "Epoch 48/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7961\n",
      "Epoch 00048: val_loss did not improve from 3.93055\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 4.7961 - val_loss: 11.1017 - lr: 7.8125e-06\n",
      "Epoch 49/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8737\n",
      "Epoch 00049: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 4.8737 - val_loss: 17.8936 - lr: 3.9063e-06\n",
      "Epoch 50/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3504\n",
      "Epoch 00050: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 4.3504 - val_loss: 11.8172 - lr: 3.9063e-06\n",
      "Epoch 51/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4782- ETA: 2s - l\n",
      "Epoch 00051: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 247ms/step - loss: 4.4782 - val_loss: 13.7378 - lr: 3.9063e-06\n",
      "Epoch 52/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 7.2007\n",
      "Epoch 00052: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 7.2007 - val_loss: 8.8913 - lr: 3.9063e-06\n",
      "Epoch 53/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.3068\n",
      "Epoch 00053: val_loss did not improve from 3.93055\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 5.3068 - val_loss: 8.2025 - lr: 3.9063e-06\n",
      "Epoch 54/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.8797\n",
      "Epoch 00054: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 5.8797 - val_loss: 12.6027 - lr: 1.9531e-06\n",
      "Epoch 55/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4073\n",
      "Epoch 00055: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 3.4073 - val_loss: 6.1673 - lr: 1.9531e-06\n",
      "Epoch 56/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5200\n",
      "Epoch 00056: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 4.5200 - val_loss: 7.0564 - lr: 1.9531e-06\n",
      "Epoch 57/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2041\n",
      "Epoch 00057: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 3.2041 - val_loss: 14.1398 - lr: 1.9531e-06\n",
      "Epoch 58/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0977\n",
      "Epoch 00058: val_loss did not improve from 3.93055\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 5.0977 - val_loss: 18.1425 - lr: 1.9531e-06\n",
      "Epoch 59/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.8710\n",
      "Epoch 00059: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 2.8710 - val_loss: 8.4245 - lr: 9.7656e-07\n",
      "Epoch 60/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6202\n",
      "Epoch 00060: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 4.6202 - val_loss: 10.6305 - lr: 9.7656e-07\n",
      "Epoch 61/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0746\n",
      "Epoch 00061: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 5.0746 - val_loss: 12.9355 - lr: 9.7656e-07\n",
      "Epoch 62/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6399\n",
      "Epoch 00062: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 3.6399 - val_loss: 6.5213 - lr: 9.7656e-07\n",
      "Epoch 63/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.7940\n",
      "Epoch 00063: val_loss did not improve from 3.93055\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "32/32 [==============================] - 8s 241ms/step - loss: 5.7940 - val_loss: 13.8626 - lr: 9.7656e-07\n",
      "Epoch 64/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.1964\n",
      "Epoch 00064: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 3.1964 - val_loss: 17.6694 - lr: 4.8828e-07\n",
      "Epoch 65/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7740\n",
      "Epoch 00065: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 3.7740 - val_loss: 25.3143 - lr: 4.8828e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7026\n",
      "Epoch 00066: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 4.7026 - val_loss: 28.9321 - lr: 4.8828e-07\n",
      "Epoch 67/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4704\n",
      "Epoch 00067: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 236ms/step - loss: 3.4704 - val_loss: 12.2536 - lr: 4.8828e-07\n",
      "Epoch 68/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0989\n",
      "Epoch 00068: val_loss did not improve from 3.93055\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 5.0989 - val_loss: 14.1054 - lr: 4.8828e-07\n",
      "Epoch 69/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7233\n",
      "Epoch 00069: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 4.7233 - val_loss: 11.3977 - lr: 2.4414e-07\n",
      "Epoch 70/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7103\n",
      "Epoch 00070: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 3.7103 - val_loss: 14.9783 - lr: 2.4414e-07\n",
      "Epoch 71/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7564\n",
      "Epoch 00071: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 4.7564 - val_loss: 17.5984 - lr: 2.4414e-07\n",
      "Epoch 72/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3168\n",
      "Epoch 00072: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 4.3168 - val_loss: 18.3376 - lr: 2.4414e-07\n",
      "Epoch 73/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.8980\n",
      "Epoch 00073: val_loss did not improve from 3.93055\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "32/32 [==============================] - 8s 236ms/step - loss: 5.8980 - val_loss: 24.5016 - lr: 2.4414e-07\n",
      "Epoch 74/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1847\n",
      "Epoch 00074: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 4.1847 - val_loss: 12.8777 - lr: 1.2207e-07\n",
      "Epoch 75/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8264\n",
      "Epoch 00075: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 3.8264 - val_loss: 22.6872 - lr: 1.2207e-07\n",
      "Epoch 76/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6280\n",
      "Epoch 00076: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 4.6280 - val_loss: 24.8164 - lr: 1.2207e-07\n",
      "Epoch 77/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9722\n",
      "Epoch 00077: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 4.9722 - val_loss: 18.7163 - lr: 1.2207e-07\n",
      "Epoch 78/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9952\n",
      "Epoch 00078: val_loss did not improve from 3.93055\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 4.9952 - val_loss: 14.7389 - lr: 1.2207e-07\n",
      "Epoch 79/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8609\n",
      "Epoch 00079: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 3.8609 - val_loss: 12.2403 - lr: 6.1035e-08\n",
      "Epoch 80/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1023\n",
      "Epoch 00080: val_loss did not improve from 3.93055\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 4.1023 - val_loss: 17.2263 - lr: 6.1035e-08\n",
      "Training Complete!!!\n"
     ]
    }
   ],
   "source": [
    "P = np.array(P)\n",
    "subs = []\n",
    "folds_history = []\n",
    "\n",
    "\"\"\"\n",
    "er = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",min_delta=1e-3,patience=15,verbose=1,mode=\"auto\",baseline=None,\n",
    "      restore_best_weights=True,) #Stop training when a monitored metric has stopped improving.\n",
    "\"\"\"\n",
    "\n",
    "cpt = tf.keras.callbacks.ModelCheckpoint(filepath=f'C:/Users/Monir/Documents/CSE499/models/EfficientNet/{MODEL_CLASS}_{EPOCHS}_epochs.h5',monitor='val_loss',verbose=1, \n",
    "    save_best_only=SAVE_BEST,mode='auto') #to save model or weights in a checkpoint file at lowest validation loss\n",
    "\n",
    "rlp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=5, verbose=1, min_lr=1e-8) \n",
    "     #Reduce learning rate when a metric has stopped improving.\n",
    "     # if improvement stops, after 5 epochs learning rate will be reduced\n",
    "\n",
    "model = build_model(model_class=MODEL_CLASS)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss=\"mae\") \n",
    "history = model.fit(IGenerator(keys=P, a = A, tab = TAB, batch_size=BATCH_SIZE), \n",
    "                    steps_per_epoch = 32,\n",
    "                    validation_data=IGenerator(keys=P, a = A, tab = TAB, batch_size=BATCH_SIZE),\n",
    "                    validation_steps = 32, \n",
    "                    callbacks = [cpt, rlp], \n",
    "                    epochs=EPOCHS)\n",
    "folds_history.append(history.history)\n",
    "print('Training Complete!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "# save to json:  \n",
    "hist_json_file = 'EffNet_b6_80_epoch_history.json' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)\n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = 'EffNet_b6_80_epoch_history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = 'C:/Users/Monir/Documents/CSE499/results_and_figures/EfficientNet/B6/'\n",
    "\n",
    "import tikzplotlib\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(EPOCHS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_range, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.savefig(result_dir + 'b6_80_epoch_oss.png')\n",
    "plt.savefig(result_dir + 'b6_80_epoch_loss.pdf', dpi=150)\n",
    "tikzplotlib.save(result_dir + 'b6_80_epoch_loss.tex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.85):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_range = range(20,EPOCHS)\n",
    "\n",
    "plt.plot(epochs_range,\n",
    "         smooth_curve(loss[20:]), 'bo', label='Training loss')\n",
    "plt.plot(epochs_range,\n",
    "         smooth_curve(val_loss[20:]), 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.savefig(result_dir + 'b6_80_epoch_loss_smooth.png')\n",
    "plt.savefig(result_dir + 'b6_80_epoch_smooth.pdf', dpi=150)\n",
    "tikzplotlib.save(result_dir + 'b6_80_epoch_smooth.tex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
