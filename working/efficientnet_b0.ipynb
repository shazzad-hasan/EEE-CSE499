{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/CSE499/osic-pulmonary-fibrosis-progression/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
       "0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker\n",
       "1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker\n",
       "2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker\n",
       "3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker\n",
       "4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153.145377828922"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Percent'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.877576671694303"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Percent'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ex-smoker', 'Never smoked', 'Currently smokes'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SmokingStatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tab(df):\n",
    "    \" return an array which contains each patient normalized age, sex and smoking status\"\n",
    "    vector = [(df.Age.values[0] - 30) / 30] \n",
    "    \n",
    "    if df.Sex.values[0].lower() == 'male':\n",
    "       vector.append(0)\n",
    "    else:\n",
    "       vector.append(1)\n",
    "    \n",
    "    if df.SmokingStatus.values[0] == 'Never smoked':\n",
    "        vector.extend([0,0])\n",
    "    elif df.SmokingStatus.values[0] == 'Ex-smoker':\n",
    "        vector.extend([1,1])\n",
    "    elif df.SmokingStatus.values[0] == 'Currently smokes':\n",
    "        vector.extend([0,1])\n",
    "    else:\n",
    "        vector.extend([1,0])\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a571ba40347441ceb5d94cd95bd0dadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Monir\\anaconda3\\envs\\rabbi36\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "A = {} \n",
    "TAB = {} \n",
    "P = [] \n",
    "for i, p in tqdm(enumerate(train.Patient.unique())): # i index, p patient id\n",
    "    sub = train.loc[train.Patient == p, :] # find all data (weeks, FVC, Percent, Age, Sex, SmokingStatus) of a unique patient\n",
    "    fvc = sub.FVC.values # fvc values of the patient during the follow-up\n",
    "    weeks = sub.Weeks.values # follow-up weeks\n",
    "    c = np.vstack([weeks, np.ones(len(weeks))]).T # create an array by the follow-up weeks of shape(len(weeks),2)\n",
    "    a, b = np.linalg.lstsq(c, fvc)[0] # least-square sol, a=gradient matrix, b=right hand matrix \n",
    "    \n",
    "    A[p] = a\n",
    "    TAB[p] = get_tab(sub)\n",
    "    P.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    \" read DICOM dataset and return resize images of size (512,512,1)\"\n",
    "    d = pydicom.dcmread(path) # read and parse the CT scan images (in DICOM format)\n",
    "    resized_image = cv2.resize((d.pixel_array - d.RescaleIntercept) / (d.RescaleSlope * 1000), (512,512))\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class IGenerator(Sequence):\n",
    "    BAD_ID = ['ID00011637202177653955184', 'ID00052637202186188008618']\n",
    "    def __init__(self, keys, a, tab, batch_size):\n",
    "        \"key=patient, a=gradient matrix, tab=a particular patient's data\"\n",
    "        self.keys = [k for k in keys if k not in self.BAD_ID]\n",
    "        self.a = a\n",
    "        self.tab = tab\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_data = {}\n",
    "        for p in train.Patient.values:\n",
    "            self.train_data[p] = os.listdir(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{p}/')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = []\n",
    "        a, tab = [], [] \n",
    "        keys = np.random.choice(self.keys, size = self.batch_size) # randomly chooses n=batch_size number of patients\n",
    "        for k in keys:\n",
    "            try:\n",
    "                i = np.random.choice(self.train_data[k], size=1)[0] # chooses some randomly images for kth patient\n",
    "                img = get_img(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{k}/{i}') # resizes ith image of kth patient\n",
    "                x.append(img) # append kth patient's image data in the list x\n",
    "                a.append(self.a[k]) # append kth patient's gradinet in the list a\n",
    "                tab.append(self.tab[k]) # append kth patient's tabular data in the tab list\n",
    "            except:\n",
    "                print(k, i)\n",
    "       \n",
    "        x,a,tab = np.array(x), np.array(a), np.array(tab) # convert list to array\n",
    "        x = np.expand_dims(x, axis=-1) \n",
    "        return [x, tab] , a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Activation, Flatten, Input, BatchNormalization, GlobalAveragePooling2D, GaussianNoise, \n",
    "    Add, Conv2D, AveragePooling2D, LeakyReLU, Concatenate \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "def get_model(model, shape):\n",
    "    models_dict = {\n",
    "        'b0': efn.EfficientNetB0(input_shape=shape,weights=None,include_top=False),\n",
    "        'b1': efn.EfficientNetB1(input_shape=shape,weights=None,include_top=False),\n",
    "        'b2': efn.EfficientNetB2(input_shape=shape,weights=None,include_top=False),\n",
    "        'b3': efn.EfficientNetB3(input_shape=shape,weights=None,include_top=False),\n",
    "        'b4': efn.EfficientNetB4(input_shape=shape,weights=None,include_top=False),\n",
    "        'b5': efn.EfficientNetB5(input_shape=shape,weights=None,include_top=False),\n",
    "        'b6': efn.EfficientNetB6(input_shape=shape,weights=None,include_top=False),\n",
    "        'b7': efn.EfficientNetB7(input_shape=shape,weights=None,include_top=False),\n",
    "        #'RNet50': resnet50.ResNet50(input_shape=shape,weights=None,include_top=False),\n",
    "        #'V16': vgg16.VGG16(input_shape=shape,weights=None,include_top=False)\n",
    "    }\n",
    "    return models_dict[model]\n",
    "\n",
    "def build_model(shape=(512, 512, 1), model_class=None):\n",
    "    inp = Input(shape=shape)\n",
    "    base = get_model(model_class, shape)\n",
    "    x = base(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    inp2 = Input(shape=(4,)) # indicates that the expected input will be batches of 4-dimensional vectors\n",
    "    x2 = GaussianNoise(0.2)(inp2) # to mitigate overfitting\n",
    "    x = Concatenate()([x, x2]) \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = Dense(1)(x)\n",
    "    model = Model([inp, inp2] , x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-b0 (Model)         (None, 16, 16, 1280) 4048988     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1280)         0           efficientnet-b0[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 4)            0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1284)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1284)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1285        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,050,273\n",
      "Trainable params: 4,008,257\n",
      "Non-trainable params: 42,016\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MODEL_CLASS = 'b0'\n",
    "base_model = build_model(shape=(512, 512, 1), model_class=MODEL_CLASS)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EPOCHS = 80\n",
    "LR = 0.001\n",
    "SAVE_BEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4413\n",
      "Epoch 00001: val_loss improved from inf to 3.95091, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 9s 292ms/step - loss: 4.4413 - val_loss: 3.9509 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6858\n",
      "Epoch 00002: val_loss did not improve from 3.95091\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 4.6858 - val_loss: 6.0858 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4526\n",
      "Epoch 00003: val_loss did not improve from 3.95091\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 4.4526 - val_loss: 4.1175 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3161\n",
      "Epoch 00004: val_loss did not improve from 3.95091\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 4.3161 - val_loss: 6.8101 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3539\n",
      "Epoch 00005: val_loss did not improve from 3.95091\n",
      "32/32 [==============================] - 7s 221ms/step - loss: 4.3539 - val_loss: 5.1218 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8414\n",
      "Epoch 00006: val_loss did not improve from 3.95091\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "32/32 [==============================] - 7s 228ms/step - loss: 3.8414 - val_loss: 49.1313 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8614\n",
      "Epoch 00007: val_loss did not improve from 3.95091\n",
      "32/32 [==============================] - 7s 224ms/step - loss: 4.8614 - val_loss: 25.2021 - lr: 5.0000e-04\n",
      "Epoch 8/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0356\n",
      "Epoch 00008: val_loss did not improve from 3.95091\n",
      "32/32 [==============================] - 7s 228ms/step - loss: 4.0356 - val_loss: 5.6396 - lr: 5.0000e-04\n",
      "Epoch 9/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0368\n",
      "Epoch 00009: val_loss did not improve from 3.95091\n",
      "32/32 [==============================] - 7s 222ms/step - loss: 4.0368 - val_loss: 4.5666 - lr: 5.0000e-04\n",
      "Epoch 10/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0251\n",
      "Epoch 00010: val_loss improved from 3.95091 to 3.90128, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 10s 309ms/step - loss: 4.0251 - val_loss: 3.9013 - lr: 5.0000e-04\n",
      "Epoch 11/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7264\n",
      "Epoch 00011: val_loss improved from 3.90128 to 3.70338, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 12s 371ms/step - loss: 4.7264 - val_loss: 3.7034 - lr: 5.0000e-04\n",
      "Epoch 12/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2495\n",
      "Epoch 00012: val_loss did not improve from 3.70338\n",
      "32/32 [==============================] - 8s 235ms/step - loss: 4.2495 - val_loss: 4.4674 - lr: 5.0000e-04\n",
      "Epoch 13/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4525\n",
      "Epoch 00013: val_loss did not improve from 3.70338\n",
      "32/32 [==============================] - 7s 219ms/step - loss: 4.4525 - val_loss: 4.1869 - lr: 5.0000e-04\n",
      "Epoch 14/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1361\n",
      "Epoch 00014: val_loss did not improve from 3.70338\n",
      "32/32 [==============================] - 7s 220ms/step - loss: 4.1361 - val_loss: 4.7479 - lr: 5.0000e-04\n",
      "Epoch 15/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3426\n",
      "Epoch 00015: val_loss did not improve from 3.70338\n",
      "32/32 [==============================] - 7s 218ms/step - loss: 4.3426 - val_loss: 4.3902 - lr: 5.0000e-04\n",
      "Epoch 16/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7280\n",
      "Epoch 00016: val_loss did not improve from 3.70338\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "32/32 [==============================] - 7s 221ms/step - loss: 3.7280 - val_loss: 4.5137 - lr: 5.0000e-04\n",
      "Epoch 17/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9294\n",
      "Epoch 00017: val_loss did not improve from 3.70338\n",
      "32/32 [==============================] - 7s 219ms/step - loss: 4.9294 - val_loss: 4.8010 - lr: 2.5000e-04\n",
      "Epoch 18/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3243\n",
      "Epoch 00018: val_loss did not improve from 3.70338\n",
      "32/32 [==============================] - 7s 215ms/step - loss: 4.3243 - val_loss: 4.2125 - lr: 2.5000e-04\n",
      "Epoch 19/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6564\n",
      "Epoch 00019: val_loss did not improve from 3.70338\n",
      "32/32 [==============================] - 7s 223ms/step - loss: 4.6564 - val_loss: 4.5996 - lr: 2.5000e-04\n",
      "Epoch 20/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8328\n",
      "Epoch 00020: val_loss improved from 3.70338 to 3.52435, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 3.8328 - val_loss: 3.5243 - lr: 2.5000e-04\n",
      "Epoch 21/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4631\n",
      "Epoch 00021: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 229ms/step - loss: 4.4631 - val_loss: 4.2589 - lr: 2.5000e-04\n",
      "Epoch 22/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5665\n",
      "Epoch 00022: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 205ms/step - loss: 4.5665 - val_loss: 5.6890 - lr: 2.5000e-04\n",
      "Epoch 23/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4479\n",
      "Epoch 00023: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 211ms/step - loss: 4.4479 - val_loss: 5.1270 - lr: 2.5000e-04\n",
      "Epoch 24/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1156\n",
      "Epoch 00024: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 210ms/step - loss: 4.1156 - val_loss: 3.7631 - lr: 2.5000e-04\n",
      "Epoch 25/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1732\n",
      "Epoch 00025: val_loss did not improve from 3.52435\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "32/32 [==============================] - 7s 208ms/step - loss: 4.1732 - val_loss: 4.7028 - lr: 2.5000e-04\n",
      "Epoch 26/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4014\n",
      "Epoch 00026: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 209ms/step - loss: 4.4014 - val_loss: 3.7136 - lr: 1.2500e-04\n",
      "Epoch 27/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7525\n",
      "Epoch 00027: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 210ms/step - loss: 4.7525 - val_loss: 4.6100 - lr: 1.2500e-04\n",
      "Epoch 28/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8411\n",
      "Epoch 00028: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 3.8411 - val_loss: 5.1115 - lr: 1.2500e-04\n",
      "Epoch 29/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0087\n",
      "Epoch 00029: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 210ms/step - loss: 4.0087 - val_loss: 4.9538 - lr: 1.2500e-04\n",
      "Epoch 30/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4572\n",
      "Epoch 00030: val_loss did not improve from 3.52435\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "32/32 [==============================] - 7s 208ms/step - loss: 4.4572 - val_loss: 7.1207 - lr: 1.2500e-04\n",
      "Epoch 31/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8734\n",
      "Epoch 00031: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 214ms/step - loss: 4.8734 - val_loss: 4.8618 - lr: 6.2500e-05\n",
      "Epoch 32/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.4583\n",
      "Epoch 00032: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 208ms/step - loss: 5.4583 - val_loss: 4.1867 - lr: 6.2500e-05\n",
      "Epoch 33/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3057\n",
      "Epoch 00033: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 207ms/step - loss: 4.3057 - val_loss: 5.6300 - lr: 6.2500e-05\n",
      "Epoch 34/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7879\n",
      "Epoch 00034: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 211ms/step - loss: 3.7879 - val_loss: 5.2337 - lr: 6.2500e-05\n",
      "Epoch 35/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7996\n",
      "Epoch 00035: val_loss did not improve from 3.52435\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "32/32 [==============================] - 7s 214ms/step - loss: 3.7996 - val_loss: 3.9146 - lr: 6.2500e-05\n",
      "Epoch 36/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8757\n",
      "Epoch 00036: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 3.8757 - val_loss: 4.1142 - lr: 3.1250e-05\n",
      "Epoch 37/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5878\n",
      "Epoch 00037: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 218ms/step - loss: 4.5878 - val_loss: 3.7991 - lr: 3.1250e-05\n",
      "Epoch 38/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4907\n",
      "Epoch 00038: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 209ms/step - loss: 4.4907 - val_loss: 5.1311 - lr: 3.1250e-05\n",
      "Epoch 39/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0850\n",
      "Epoch 00039: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 4.0850 - val_loss: 4.3974 - lr: 3.1250e-05\n",
      "Epoch 40/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0903\n",
      "Epoch 00040: val_loss did not improve from 3.52435\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 4.0903 - val_loss: 4.0548 - lr: 3.1250e-05\n",
      "Epoch 41/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0905\n",
      "Epoch 00041: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 5.0905 - val_loss: 4.2636 - lr: 1.5625e-05\n",
      "Epoch 42/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4558\n",
      "Epoch 00042: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 205ms/step - loss: 4.4558 - val_loss: 5.0525 - lr: 1.5625e-05\n",
      "Epoch 43/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1011\n",
      "Epoch 00043: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 211ms/step - loss: 4.1011 - val_loss: 4.0154 - lr: 1.5625e-05\n",
      "Epoch 44/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8690\n",
      "Epoch 00044: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 3.8690 - val_loss: 4.0301 - lr: 1.5625e-05\n",
      "Epoch 45/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0856\n",
      "Epoch 00045: val_loss did not improve from 3.52435\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "32/32 [==============================] - 7s 206ms/step - loss: 4.0856 - val_loss: 4.7581 - lr: 1.5625e-05\n",
      "Epoch 46/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9722\n",
      "Epoch 00046: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 4.9722 - val_loss: 3.9233 - lr: 7.8125e-06\n",
      "Epoch 47/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9864\n",
      "Epoch 00047: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 4.9864 - val_loss: 4.1285 - lr: 7.8125e-06\n",
      "Epoch 48/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5514\n",
      "Epoch 00048: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 4.5514 - val_loss: 4.7146 - lr: 7.8125e-06\n",
      "Epoch 49/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1255\n",
      "Epoch 00049: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 4.1255 - val_loss: 4.3113 - lr: 7.8125e-06\n",
      "Epoch 50/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6312\n",
      "Epoch 00050: val_loss did not improve from 3.52435\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 4.6312 - val_loss: 5.0394 - lr: 7.8125e-06\n",
      "Epoch 51/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9287\n",
      "Epoch 00051: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 3.9287 - val_loss: 4.9122 - lr: 3.9063e-06\n",
      "Epoch 52/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2631\n",
      "Epoch 00052: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 4.2631 - val_loss: 3.5486 - lr: 3.9063e-06\n",
      "Epoch 53/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2393\n",
      "Epoch 00053: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 197ms/step - loss: 4.2393 - val_loss: 4.3233 - lr: 3.9063e-06\n",
      "Epoch 54/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2011\n",
      "Epoch 00054: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 4.2011 - val_loss: 4.6150 - lr: 3.9063e-06\n",
      "Epoch 55/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5170\n",
      "Epoch 00055: val_loss did not improve from 3.52435\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "32/32 [==============================] - 7s 209ms/step - loss: 4.5170 - val_loss: 4.6086 - lr: 3.9063e-06\n",
      "Epoch 56/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9248\n",
      "Epoch 00056: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 3.9248 - val_loss: 4.3495 - lr: 1.9531e-06\n",
      "Epoch 57/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7131\n",
      "Epoch 00057: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 4.7131 - val_loss: 3.9275 - lr: 1.9531e-06\n",
      "Epoch 58/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7418\n",
      "Epoch 00058: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 197ms/step - loss: 3.7418 - val_loss: 5.4972 - lr: 1.9531e-06\n",
      "Epoch 59/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4577\n",
      "Epoch 00059: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 4.4577 - val_loss: 4.5454 - lr: 1.9531e-06\n",
      "Epoch 60/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.2383\n",
      "Epoch 00060: val_loss did not improve from 3.52435\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 5.2383 - val_loss: 5.5601 - lr: 1.9531e-06\n",
      "Epoch 61/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6217\n",
      "Epoch 00061: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 4.6217 - val_loss: 5.3856 - lr: 9.7656e-07\n",
      "Epoch 62/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3695\n",
      "Epoch 00062: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 4.3695 - val_loss: 5.1303 - lr: 9.7656e-07\n",
      "Epoch 63/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9962\n",
      "Epoch 00063: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 4.9962 - val_loss: 4.6424 - lr: 9.7656e-07\n",
      "Epoch 64/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7343\n",
      "Epoch 00064: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 199ms/step - loss: 3.7343 - val_loss: 4.5257 - lr: 9.7656e-07\n",
      "Epoch 65/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6829\n",
      "Epoch 00065: val_loss did not improve from 3.52435\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "32/32 [==============================] - 7s 205ms/step - loss: 4.6829 - val_loss: 4.3619 - lr: 9.7656e-07\n",
      "Epoch 66/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0910\n",
      "Epoch 00066: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 4.0910 - val_loss: 4.1079 - lr: 4.8828e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4169\n",
      "Epoch 00067: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 191ms/step - loss: 4.4169 - val_loss: 4.1186 - lr: 4.8828e-07\n",
      "Epoch 68/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5131\n",
      "Epoch 00068: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 197ms/step - loss: 4.5131 - val_loss: 5.1289 - lr: 4.8828e-07\n",
      "Epoch 69/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4835\n",
      "Epoch 00069: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 3.4835 - val_loss: 5.0908 - lr: 4.8828e-07\n",
      "Epoch 70/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7272\n",
      "Epoch 00070: val_loss did not improve from 3.52435\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 3.7272 - val_loss: 3.7889 - lr: 4.8828e-07\n",
      "Epoch 71/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4409\n",
      "Epoch 00071: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 4.4409 - val_loss: 4.4149 - lr: 2.4414e-07\n",
      "Epoch 72/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6971\n",
      "Epoch 00072: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 197ms/step - loss: 4.6971 - val_loss: 3.7755 - lr: 2.4414e-07\n",
      "Epoch 73/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9262\n",
      "Epoch 00073: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 3.9262 - val_loss: 4.8009 - lr: 2.4414e-07\n",
      "Epoch 74/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7571\n",
      "Epoch 00074: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 3.7571 - val_loss: 4.8971 - lr: 2.4414e-07\n",
      "Epoch 75/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3283\n",
      "Epoch 00075: val_loss did not improve from 3.52435\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 4.3283 - val_loss: 4.9401 - lr: 2.4414e-07\n",
      "Epoch 76/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9278\n",
      "Epoch 00076: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 3.9278 - val_loss: 4.2545 - lr: 1.2207e-07\n",
      "Epoch 77/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4382\n",
      "Epoch 00077: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 4.4382 - val_loss: 4.2890 - lr: 1.2207e-07\n",
      "Epoch 78/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0371\n",
      "Epoch 00078: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 4.0371 - val_loss: 5.0037 - lr: 1.2207e-07\n",
      "Epoch 79/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3480\n",
      "Epoch 00079: val_loss did not improve from 3.52435\n",
      "32/32 [==============================] - 6s 192ms/step - loss: 4.3480 - val_loss: 4.8745 - lr: 1.2207e-07\n",
      "Epoch 80/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8264\n",
      "Epoch 00080: val_loss did not improve from 3.52435\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 3.8264 - val_loss: 4.4847 - lr: 1.2207e-07\n",
      "Training Complete!!!\n"
     ]
    }
   ],
   "source": [
    "P = np.array(P)\n",
    "subs = []\n",
    "folds_history = []\n",
    "\n",
    "\"\"\"\n",
    "er = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",min_delta=1e-3,patience=15,verbose=1,mode=\"auto\",baseline=None,\n",
    "      restore_best_weights=True,) #Stop training when a monitored metric has stopped improving.\n",
    "\"\"\"\n",
    "\n",
    "cpt = tf.keras.callbacks.ModelCheckpoint(filepath=f'{MODEL_CLASS}_{EPOCHS}_epochs.h5',monitor='val_loss',verbose=1, \n",
    "    save_best_only=SAVE_BEST,mode='auto') #to save model or weights in a checkpoint file at lowest validation loss\n",
    "\n",
    "rlp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=5, verbose=1, min_lr=1e-8) \n",
    "     #Reduce learning rate when a metric has stopped improving.\n",
    "     # if improvement stops, after 5 epochs learning rate will be reduced\n",
    "\n",
    "model = build_model(model_class=MODEL_CLASS)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss=\"mae\") \n",
    "history = model.fit(IGenerator(keys=P, a = A, tab = TAB, batch_size=BATCH_SIZE), \n",
    "                    steps_per_epoch = 32,\n",
    "                    validation_data=IGenerator(keys=P, a = A, tab = TAB, batch_size=BATCH_SIZE),\n",
    "                    validation_steps = 32, \n",
    "                    callbacks = [cpt, rlp], \n",
    "                    epochs=EPOCHS)\n",
    "folds_history.append(history.history)\n",
    "print('Training Complete!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "# save to json:  \n",
    "hist_json_file = 'EffNet_b0_history_80_epoch.json' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)\n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = 'EffNet_b0_history_80_epoch.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = 'C:/Users/Monir/Documents/CSE499/results_and_figures/EfficientNet/B0/'\n",
    "\n",
    "import tikzplotlib\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(EPOCHS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_range, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(result_dir + 'b0_80_epoch_loss.png')\n",
    "plt.savefig(result_dir + 'b0_80_epoch_loss.pdf', dpi=150)\n",
    "tikzplotlib.save(result_dir + 'b0_80_epoch_loss.tex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.85):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_range = range(20,EPOCHS)\n",
    "plt.plot(epochs_range,\n",
    "         smooth_curve(loss[20:]), 'bo', label='Training loss')\n",
    "plt.plot(epochs_range,\n",
    "         smooth_curve(val_loss[20:]), 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.savefig(result_dir + 'b0_80_epoch_loss_smooth.png')\n",
    "plt.savefig(result_dir + 'b0_80_epoch_loss_smooth.pdf', dpi=150)\n",
    "tikzplotlib.save(result_dir + 'b0_80_epoch_loss_smooth.tex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
