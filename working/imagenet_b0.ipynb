{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pydicom\n",
    "import tikzplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import efficientnet.tfkeras as efn\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Activation, Flatten, Input, BatchNormalization, GlobalAveragePooling2D, GaussianNoise, \n",
    "    Add, Conv2D, AveragePooling2D, LeakyReLU, Concatenate \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/CSE499/osic-pulmonary-fibrosis-progression/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
       "0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker\n",
       "1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker\n",
       "2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker\n",
       "3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker\n",
       "4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153.145377828922"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Percent'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.877576671694303"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Percent'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ex-smoker', 'Never smoked', 'Currently smokes'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SmokingStatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tab(df):\n",
    "    \" return an array which contains each patient normalized age, sex and smoking status\"\n",
    "    vector = [(df.Age.values[0] - 30) / 30] \n",
    "    \n",
    "    if df.Sex.values[0].lower() == 'male':\n",
    "       vector.append(0)\n",
    "    else:\n",
    "       vector.append(1)\n",
    "    \n",
    "    if df.SmokingStatus.values[0] == 'Never smoked':\n",
    "        vector.extend([0,0])\n",
    "    elif df.SmokingStatus.values[0] == 'Ex-smoker':\n",
    "        vector.extend([1,1])\n",
    "    elif df.SmokingStatus.values[0] == 'Currently smokes':\n",
    "        vector.extend([0,1])\n",
    "    else:\n",
    "        vector.extend([1,0])\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2291e40cb80a4e359e793279b9a077af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Monir\\anaconda3\\envs\\rabbi36\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "A = {} \n",
    "TAB = {} \n",
    "P = [] \n",
    "for i, p in tqdm(enumerate(train.Patient.unique())): # i index, p patient id\n",
    "    sub = train.loc[train.Patient == p, :] # find all data (weeks, FVC, Percent, Age, Sex, SmokingStatus) of a unique patient\n",
    "    fvc = sub.FVC.values # fvc values of the patient during the follow-up\n",
    "    weeks = sub.Weeks.values # follow-up weeks\n",
    "    c = np.vstack([weeks, np.ones(len(weeks))]).T # create an array by the follow-up weeks of shape(len(weeks),2)\n",
    "    a, b = np.linalg.lstsq(c, fvc)[0] # least-square sol, a=gradient matrix, b=right hand matrix \n",
    "    \n",
    "    A[p] = a\n",
    "    TAB[p] = get_tab(sub)\n",
    "    P.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    \" read DICOM dataset and return resize images of size (512,512,3)\"\n",
    "    d = pydicom.dcmread(path) # read and parse the CT scan images (in DICOM format)\n",
    "    resized_image = cv2.resize((d.pixel_array - d.RescaleIntercept) / (d.RescaleSlope * 1000), (512,512))\n",
    "    resized_image = np.stack((resized_image,)*3, axis = -1)\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class IGenerator(Sequence):\n",
    "    BAD_ID = ['ID00011637202177653955184', 'ID00052637202186188008618']\n",
    "    def __init__(self, keys, a, tab, batch_size):\n",
    "        \"key=patient, a=gradient matrix, tab=a particular patient's data\"\n",
    "        self.keys = [k for k in keys if k not in self.BAD_ID]\n",
    "        self.a = a\n",
    "        self.tab = tab\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_data = {}\n",
    "        for p in train.Patient.values:\n",
    "            self.train_data[p] = os.listdir(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{p}/')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = []\n",
    "        a, tab = [], [] \n",
    "        keys = np.random.choice(self.keys, size = self.batch_size) # randomly chooses n=batch_size number of patients\n",
    "        for k in keys:\n",
    "            try:\n",
    "                i = np.random.choice(self.train_data[k], size=1)[0] # chooses some randomly images for kth patient\n",
    "                img = get_img(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{k}/{i}') # resizes ith image of kth patient\n",
    "                x.append(img) # append kth patient's image data in the list x\n",
    "                a.append(self.a[k]) # append kth patient's gradinet in the list a\n",
    "                tab.append(self.tab[k]) # append kth patient's tabular data in the tab list\n",
    "            except:\n",
    "                print(k, i)\n",
    "       \n",
    "        x,a,tab = np.array(x), np.array(a), np.array(tab) # convert list to array\n",
    "        #x = np.expand_dims(x, axis=-1) \n",
    "        return [x, tab] , a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model, shape):\n",
    "    models_dict = {\n",
    "        'b0': efn.EfficientNetB0(input_shape=shape,weights='imagenet',include_top=False),\n",
    "        'b1': efn.EfficientNetB1(input_shape=shape,weights=None,include_top=False),\n",
    "        'b2': efn.EfficientNetB2(input_shape=shape,weights=None,include_top=False),\n",
    "        'b3': efn.EfficientNetB3(input_shape=shape,weights=None,include_top=False),\n",
    "        'b4': efn.EfficientNetB4(input_shape=shape,weights=None,include_top=False),\n",
    "        'b5': efn.EfficientNetB5(input_shape=shape,weights=None,include_top=False),\n",
    "        'b6': efn.EfficientNetB6(input_shape=shape,weights=None,include_top=False),\n",
    "        'b7': efn.EfficientNetB7(input_shape=shape,weights=None,include_top=False),\n",
    "        #'RNet50': resnet50.ResNet50(input_shape=shape,weights=None,include_top=False),\n",
    "        #'V16': vgg16.VGG16(input_shape=shape,weights=None,include_top=False)\n",
    "    }\n",
    "    return models_dict[model]\n",
    "\n",
    "def build_model(shape=(512, 512, 3), model_class=None):\n",
    "    inp = Input(shape=shape)\n",
    "    base = get_model(model_class, shape)\n",
    "    x = base(inp)\n",
    "    x.trainable = False\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    inp2 = Input(shape=(4,)) # indicates that the expected input will be batches of 4-dimensional vectors\n",
    "    x2 = GaussianNoise(0.2)(inp2) # to mitigate overfitting\n",
    "    x = Concatenate()([x, x2]) \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = Dense(1)(x)\n",
    "    model = Model([inp, inp2] , x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-b0 (Model)         (None, 16, 16, 1280) 4049564     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1280)         0           efficientnet-b0[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 4)            0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1284)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1284)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1285        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,050,849\n",
      "Trainable params: 4,008,833\n",
      "Non-trainable params: 42,016\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MODEL_CLASS = 'b0'\n",
    "base_model = build_model(shape=(512, 512, 3), model_class=MODEL_CLASS)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EPOCHS = 80\n",
    "LR = 0.001\n",
    "SAVE_BEST = True\n",
    "tr_p, vl_p = train_test_split(P, shuffle=True, train_size= 0.8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7002\n",
      "Epoch 00001: val_loss improved from inf to 8.11156, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 15s 464ms/step - loss: 4.7002 - val_loss: 8.1116 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4511\n",
      "Epoch 00002: val_loss improved from 8.11156 to 5.01315, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 15s 473ms/step - loss: 4.4511 - val_loss: 5.0131 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6892\n",
      "Epoch 00003: val_loss improved from 5.01315 to 4.77192, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 13s 392ms/step - loss: 3.6892 - val_loss: 4.7719 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0632\n",
      "Epoch 00004: val_loss did not improve from 4.77192\n",
      "32/32 [==============================] - 10s 302ms/step - loss: 4.0632 - val_loss: 9.5971 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9765\n",
      "Epoch 00005: val_loss did not improve from 4.77192\n",
      "32/32 [==============================] - 9s 274ms/step - loss: 3.9765 - val_loss: 5.3390 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.1194\n",
      "Epoch 00006: val_loss did not improve from 4.77192\n",
      "32/32 [==============================] - 9s 271ms/step - loss: 5.1194 - val_loss: 5.6469 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6145\n",
      "Epoch 00007: val_loss improved from 4.77192 to 4.76940, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 4.6145 - val_loss: 4.7694 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2859\n",
      "Epoch 00008: val_loss did not improve from 4.76940\n",
      "32/32 [==============================] - 9s 271ms/step - loss: 4.2859 - val_loss: 6.1545 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8820\n",
      "Epoch 00009: val_loss improved from 4.76940 to 4.62536, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 12s 379ms/step - loss: 3.8820 - val_loss: 4.6254 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0742\n",
      "Epoch 00010: val_loss did not improve from 4.62536\n",
      "32/32 [==============================] - 9s 275ms/step - loss: 4.0742 - val_loss: 4.6715 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0411\n",
      "Epoch 00011: val_loss improved from 4.62536 to 4.04601, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 12s 389ms/step - loss: 5.0411 - val_loss: 4.0460 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3864\n",
      "Epoch 00012: val_loss did not improve from 4.04601\n",
      "32/32 [==============================] - 8s 255ms/step - loss: 4.3864 - val_loss: 4.5060 - lr: 0.0010\n",
      "Epoch 13/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5668\n",
      "Epoch 00013: val_loss did not improve from 4.04601\n",
      "32/32 [==============================] - 8s 257ms/step - loss: 4.5668 - val_loss: 4.4521 - lr: 0.0010\n",
      "Epoch 14/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1392\n",
      "Epoch 00014: val_loss did not improve from 4.04601\n",
      "32/32 [==============================] - 8s 257ms/step - loss: 4.1392 - val_loss: 4.4112 - lr: 0.0010\n",
      "Epoch 15/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4869\n",
      "Epoch 00015: val_loss did not improve from 4.04601\n",
      "32/32 [==============================] - 8s 261ms/step - loss: 3.4869 - val_loss: 4.4123 - lr: 0.0010\n",
      "Epoch 16/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9481\n",
      "Epoch 00016: val_loss improved from 4.04601 to 3.98040, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 13s 398ms/step - loss: 3.9481 - val_loss: 3.9804 - lr: 0.0010\n",
      "Epoch 17/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0240\n",
      "Epoch 00017: val_loss improved from 3.98040 to 3.92481, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 12s 360ms/step - loss: 4.0240 - val_loss: 3.9248 - lr: 0.0010\n",
      "Epoch 18/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6124\n",
      "Epoch 00018: val_loss did not improve from 3.92481\n",
      "32/32 [==============================] - 8s 261ms/step - loss: 4.6124 - val_loss: 4.3722 - lr: 0.0010\n",
      "Epoch 19/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7701\n",
      "Epoch 00019: val_loss did not improve from 3.92481\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 3.7701 - val_loss: 4.8040 - lr: 0.0010\n",
      "Epoch 20/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2176\n",
      "Epoch 00020: val_loss did not improve from 3.92481\n",
      "32/32 [==============================] - 8s 251ms/step - loss: 4.2176 - val_loss: 4.3279 - lr: 0.0010\n",
      "Epoch 21/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3357\n",
      "Epoch 00021: val_loss did not improve from 3.92481\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 4.3357 - val_loss: 5.1778 - lr: 0.0010\n",
      "Epoch 22/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0801\n",
      "Epoch 00022: val_loss did not improve from 3.92481\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "32/32 [==============================] - 8s 246ms/step - loss: 4.0801 - val_loss: 6.6362 - lr: 0.0010\n",
      "Epoch 23/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3071\n",
      "Epoch 00023: val_loss did not improve from 3.92481\n",
      "32/32 [==============================] - 8s 252ms/step - loss: 4.3071 - val_loss: 4.6815 - lr: 5.0000e-04\n",
      "Epoch 24/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7330\n",
      "Epoch 00024: val_loss improved from 3.92481 to 3.85627, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 12s 360ms/step - loss: 3.7330 - val_loss: 3.8563 - lr: 5.0000e-04\n",
      "Epoch 25/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5704\n",
      "Epoch 00025: val_loss improved from 3.85627 to 3.61455, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 13s 400ms/step - loss: 4.5704 - val_loss: 3.6146 - lr: 5.0000e-04\n",
      "Epoch 26/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7674\n",
      "Epoch 00026: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 8s 258ms/step - loss: 3.7674 - val_loss: 4.4908 - lr: 5.0000e-04\n",
      "Epoch 27/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9323\n",
      "Epoch 00027: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 3.9323 - val_loss: 4.4895 - lr: 5.0000e-04\n",
      "Epoch 28/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5944\n",
      "Epoch 00028: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 8s 238ms/step - loss: 4.5944 - val_loss: 4.4555 - lr: 5.0000e-04\n",
      "Epoch 29/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.2458\n",
      "Epoch 00029: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 5.2458 - val_loss: 4.4432 - lr: 5.0000e-04\n",
      "Epoch 30/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6771\n",
      "Epoch 00030: val_loss did not improve from 3.61455\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "32/32 [==============================] - 8s 236ms/step - loss: 4.6771 - val_loss: 4.4197 - lr: 5.0000e-04\n",
      "Epoch 31/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.5041\n",
      "Epoch 00031: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 5.5041 - val_loss: 3.9746 - lr: 2.5000e-04\n",
      "Epoch 32/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7482\n",
      "Epoch 00032: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 8s 236ms/step - loss: 4.7482 - val_loss: 4.3766 - lr: 2.5000e-04\n",
      "Epoch 33/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5200\n",
      "Epoch 00033: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 8s 236ms/step - loss: 4.5200 - val_loss: 4.5714 - lr: 2.5000e-04\n",
      "Epoch 34/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 4.2713\n",
      "Epoch 00034: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 7s 230ms/step - loss: 4.2713 - val_loss: 4.7643 - lr: 2.5000e-04\n",
      "Epoch 35/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0308\n",
      "Epoch 00035: val_loss did not improve from 3.61455\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "32/32 [==============================] - 8s 236ms/step - loss: 4.0308 - val_loss: 4.4435 - lr: 2.5000e-04\n",
      "Epoch 36/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2902\n",
      "Epoch 00036: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 7s 232ms/step - loss: 4.2902 - val_loss: 4.1502 - lr: 1.2500e-04\n",
      "Epoch 37/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1927\n",
      "Epoch 00037: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 4.1927 - val_loss: 3.7949 - lr: 1.2500e-04\n",
      "Epoch 38/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9295\n",
      "Epoch 00038: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 8s 237ms/step - loss: 3.9295 - val_loss: 3.7603 - lr: 1.2500e-04\n",
      "Epoch 39/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0577\n",
      "Epoch 00039: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 4.0577 - val_loss: 3.8740 - lr: 1.2500e-04\n",
      "Epoch 40/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5586\n",
      "Epoch 00040: val_loss did not improve from 3.61455\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "32/32 [==============================] - 7s 234ms/step - loss: 4.5586 - val_loss: 4.6080 - lr: 1.2500e-04\n",
      "Epoch 41/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0289\n",
      "Epoch 00041: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 7s 223ms/step - loss: 4.0289 - val_loss: 4.0995 - lr: 6.2500e-05\n",
      "Epoch 42/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0368\n",
      "Epoch 00042: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 4.0368 - val_loss: 3.8771 - lr: 6.2500e-05\n",
      "Epoch 43/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8738\n",
      "Epoch 00043: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 4.8738 - val_loss: 3.6805 - lr: 6.2500e-05\n",
      "Epoch 44/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2532\n",
      "Epoch 00044: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 7s 229ms/step - loss: 4.2532 - val_loss: 4.8936 - lr: 6.2500e-05\n",
      "Epoch 45/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2913\n",
      "Epoch 00045: val_loss did not improve from 3.61455\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 4.2913 - val_loss: 4.3695 - lr: 6.2500e-05\n",
      "Epoch 46/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7862\n",
      "Epoch 00046: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 8s 236ms/step - loss: 3.7862 - val_loss: 4.2569 - lr: 3.1250e-05\n",
      "Epoch 47/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6759\n",
      "Epoch 00047: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 7s 227ms/step - loss: 4.6759 - val_loss: 4.4213 - lr: 3.1250e-05\n",
      "Epoch 48/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9595\n",
      "Epoch 00048: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 7s 228ms/step - loss: 3.9595 - val_loss: 5.1131 - lr: 3.1250e-05\n",
      "Epoch 49/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1787\n",
      "Epoch 00049: val_loss did not improve from 3.61455\n",
      "32/32 [==============================] - 8s 239ms/step - loss: 4.1787 - val_loss: 4.1621 - lr: 3.1250e-05\n",
      "Epoch 50/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7319\n",
      "Epoch 00050: val_loss did not improve from 3.61455\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "32/32 [==============================] - 7s 234ms/step - loss: 3.7319 - val_loss: 4.8014 - lr: 3.1250e-05\n",
      "Epoch 51/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7393\n",
      "Epoch 00051: val_loss improved from 3.61455 to 3.20495, saving model to b0_80_epochs.h5\n",
      "32/32 [==============================] - 12s 377ms/step - loss: 4.7393 - val_loss: 3.2049 - lr: 1.5625e-05\n",
      "Epoch 52/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4561\n",
      "Epoch 00052: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 8s 250ms/step - loss: 4.4561 - val_loss: 4.1278 - lr: 1.5625e-05\n",
      "Epoch 53/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2800\n",
      "Epoch 00053: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 8s 236ms/step - loss: 4.2800 - val_loss: 4.5356 - lr: 1.5625e-05\n",
      "Epoch 54/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2202\n",
      "Epoch 00054: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 230ms/step - loss: 4.2202 - val_loss: 3.8839 - lr: 1.5625e-05\n",
      "Epoch 55/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5016\n",
      "Epoch 00055: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 223ms/step - loss: 3.5016 - val_loss: 4.4018 - lr: 1.5625e-05\n",
      "Epoch 56/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2435\n",
      "Epoch 00056: val_loss did not improve from 3.20495\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "32/32 [==============================] - 7s 228ms/step - loss: 4.2435 - val_loss: 4.3680 - lr: 1.5625e-05\n",
      "Epoch 57/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7979\n",
      "Epoch 00057: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 224ms/step - loss: 3.7979 - val_loss: 4.1713 - lr: 7.8125e-06\n",
      "Epoch 58/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0245\n",
      "Epoch 00058: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 224ms/step - loss: 4.0245 - val_loss: 3.5253 - lr: 7.8125e-06\n",
      "Epoch 59/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5479\n",
      "Epoch 00059: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 222ms/step - loss: 4.5479 - val_loss: 4.2277 - lr: 7.8125e-06\n",
      "Epoch 60/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8741\n",
      "Epoch 00060: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 229ms/step - loss: 3.8741 - val_loss: 3.9668 - lr: 7.8125e-06\n",
      "Epoch 61/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7393\n",
      "Epoch 00061: val_loss did not improve from 3.20495\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "32/32 [==============================] - 7s 228ms/step - loss: 4.7393 - val_loss: 4.0708 - lr: 7.8125e-06\n",
      "Epoch 62/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5707\n",
      "Epoch 00062: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 8s 249ms/step - loss: 3.5707 - val_loss: 3.9474 - lr: 3.9063e-06\n",
      "Epoch 63/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4966\n",
      "Epoch 00063: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 223ms/step - loss: 4.4966 - val_loss: 4.0148 - lr: 3.9063e-06\n",
      "Epoch 64/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7556\n",
      "Epoch 00064: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 3.7556 - val_loss: 4.0434 - lr: 3.9063e-06\n",
      "Epoch 65/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6024\n",
      "Epoch 00065: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 223ms/step - loss: 4.6024 - val_loss: 4.2933 - lr: 3.9063e-06\n",
      "Epoch 66/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6501\n",
      "Epoch 00066: val_loss did not improve from 3.20495\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "32/32 [==============================] - 7s 221ms/step - loss: 3.6501 - val_loss: 4.6658 - lr: 3.9063e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6954\n",
      "Epoch 00067: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 3.6954 - val_loss: 3.7512 - lr: 1.9531e-06\n",
      "Epoch 68/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7955\n",
      "Epoch 00068: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 219ms/step - loss: 3.7955 - val_loss: 4.1986 - lr: 1.9531e-06\n",
      "Epoch 69/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0233\n",
      "Epoch 00069: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 232ms/step - loss: 4.0233 - val_loss: 4.3166 - lr: 1.9531e-06\n",
      "Epoch 70/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4695\n",
      "Epoch 00070: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 223ms/step - loss: 4.4695 - val_loss: 3.7967 - lr: 1.9531e-06\n",
      "Epoch 71/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6390\n",
      "Epoch 00071: val_loss did not improve from 3.20495\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "32/32 [==============================] - 7s 222ms/step - loss: 3.6390 - val_loss: 4.5483 - lr: 1.9531e-06\n",
      "Epoch 72/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2373\n",
      "Epoch 00072: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 220ms/step - loss: 4.2373 - val_loss: 4.1084 - lr: 9.7656e-07\n",
      "Epoch 73/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8016\n",
      "Epoch 00073: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 220ms/step - loss: 3.8016 - val_loss: 4.1079 - lr: 9.7656e-07\n",
      "Epoch 74/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6974\n",
      "Epoch 00074: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 221ms/step - loss: 3.6974 - val_loss: 4.1738 - lr: 9.7656e-07\n",
      "Epoch 75/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8644\n",
      "Epoch 00075: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 223ms/step - loss: 4.8644 - val_loss: 3.9513 - lr: 9.7656e-07\n",
      "Epoch 76/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6590\n",
      "Epoch 00076: val_loss did not improve from 3.20495\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 4.6590 - val_loss: 3.9022 - lr: 9.7656e-07\n",
      "Epoch 77/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1004\n",
      "Epoch 00077: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 224ms/step - loss: 4.1004 - val_loss: 3.4238 - lr: 4.8828e-07\n",
      "Epoch 78/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2425\n",
      "Epoch 00078: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 223ms/step - loss: 4.2425 - val_loss: 4.3161 - lr: 4.8828e-07\n",
      "Epoch 79/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0570\n",
      "Epoch 00079: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 219ms/step - loss: 4.0570 - val_loss: 4.4045 - lr: 4.8828e-07\n",
      "Epoch 80/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3502\n",
      "Epoch 00080: val_loss did not improve from 3.20495\n",
      "32/32 [==============================] - 7s 220ms/step - loss: 4.3502 - val_loss: 4.3613 - lr: 4.8828e-07\n",
      "Training Complete!!!\n"
     ]
    }
   ],
   "source": [
    "P = np.array(P)\n",
    "subs = []\n",
    "folds_history = []\n",
    "\n",
    "\"\"\"\n",
    "er = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",min_delta=1e-3,patience=15,verbose=1,mode=\"auto\",baseline=None,\n",
    "      restore_best_weights=True,) #Stop training when a monitored metric has stopped improving.\n",
    "\"\"\"\n",
    "\n",
    "cpt = tf.keras.callbacks.ModelCheckpoint(filepath=f'{MODEL_CLASS}_{EPOCHS}_epochs.h5',monitor='val_loss',verbose=1, \n",
    "    save_best_only=SAVE_BEST,mode='auto') #to save model or weights in a checkpoint file at lowest validation loss\n",
    "\n",
    "rlp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=5, verbose=1, min_lr=1e-8) \n",
    "     #Reduce learning rate when a metric has stopped improving.\n",
    "     # if improvement stops, after 5 epochs learning rate will be reduced\n",
    "\n",
    "model = build_model(model_class=MODEL_CLASS)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss=\"mae\") \n",
    "history = model.fit(IGenerator(keys=tr_p, a = A, tab = TAB, batch_size=BATCH_SIZE), \n",
    "                    steps_per_epoch = 32,\n",
    "                    validation_data=IGenerator(keys=vl_p, a = A, tab = TAB, batch_size=BATCH_SIZE),\n",
    "                    validation_steps = 32, \n",
    "                    callbacks = [cpt, rlp], \n",
    "                    epochs=EPOCHS)\n",
    "folds_history.append(history.history)\n",
    "print('Training Complete!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "# save to json:  \n",
    "hist_json_file = 'EffNet_b0_history_80_epoch_imagenet.json' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)\n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = 'EffNet_b0_history_80_epoch_imagenet.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = 'C:/Users/Monir/Documents/CSE499/results_and_figures/EfficientNet/B0/'\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(EPOCHS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_range, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(result_dir + 'b0_80_epoch_loss_imagenet.png')\n",
    "plt.savefig(result_dir + 'b0_80_epoch_loss_imagenet.pdf', dpi=150)\n",
    "tikzplotlib.save(result_dir + 'b0_80_epoch_loss_imagenet.tex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.9):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_range = range(20,EPOCHS)\n",
    "plt.plot(epochs_range,\n",
    "         smooth_curve(loss[20:]), 'bo', label='Training loss')\n",
    "plt.plot(epochs_range,\n",
    "         smooth_curve(val_loss[20:]), 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.savefig(result_dir + 'b0_80_epoch_loss_smooth_imagenet.png')\n",
    "plt.savefig(result_dir + 'b0_80_epoch_loss_smooth_imagenet.pdf', dpi=150)\n",
    "tikzplotlib.save(result_dir + 'b0_80_epoch_loss_smooth_imagenet.tex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(fvc_true, fvc_pred, sigma):\n",
    "    sigma_clip = np.maximum(sigma, 70)\n",
    "    delta = np.abs(fvc_true - fvc_pred)\n",
    "    delta = np.minimum(delta, 1000)\n",
    "    sq2 = np.sqrt(2)\n",
    "    metric = (delta / sigma_clip)*sq2 + np.log(sigma_clip* sq2)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3330ffe273a423e95756c3d0807f63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.666543377023837\n",
      "6.683889660149324\n",
      "6.693140257062011\n",
      "6.701025305882696\n",
      "6.708289593072168\n",
      "6.719876136865974\n",
      "6.73387331794719\n",
      "6.747484426606877\n",
      "6.761458278579007\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metric = []\n",
    "for q in tqdm(range(1, 10)):\n",
    "    m = []\n",
    "    for p in vl_p:\n",
    "        x = [] \n",
    "        tab = [] \n",
    "        \n",
    "        if p in ['ID00011637202177653955184', 'ID00052637202186188008618']:\n",
    "            continue\n",
    "        for i in os.listdir(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{p}/'):\n",
    "            x.append(get_img(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{p}/{i}')) \n",
    "            tab.append(get_tab(train.loc[train.Patient == p, :])) \n",
    "        tab = np.array(tab) \n",
    "    \n",
    "        x = np.expand_dims(x, axis=-1) \n",
    "        _a = model.predict([x, tab]) \n",
    "        a = np.quantile(_a, q / 10)\n",
    "        \n",
    "        percent_true = train.Percent.values[train.Patient == p]\n",
    "        fvc_true = train.FVC.values[train.Patient == p]\n",
    "        weeks_true = train.Weeks.values[train.Patient == p]\n",
    "        \n",
    "        fvc = a * (weeks_true - weeks_true[0]) + fvc_true[0]\n",
    "        percent = percent_true[0] - a * abs(weeks_true - weeks_true[0])\n",
    "        m.append(score(fvc_true, fvc, percent))\n",
    "    print(np.mean(m))\n",
    "    metric.append(np.mean(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = (np.argmin(metric) + 1)/ 10\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Week</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00419637202311204720264_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00421637202311550012437_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00422637202311677017371_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00423637202312137826377_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00426637202313170790466_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Patient_Week   FVC  Confidence\n",
       "0  ID00419637202311204720264_-12  2000         100\n",
       "1  ID00421637202311550012437_-12  2000         100\n",
       "2  ID00422637202311677017371_-12  2000         100\n",
       "3  ID00423637202312137826377_-12  2000         100\n",
       "4  ID00426637202313170790466_-12  2000         100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('D:/CSE499/osic-pulmonary-fibrosis-progression/sample_submission.csv') \n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00419637202311204720264</td>\n",
       "      <td>6</td>\n",
       "      <td>3020</td>\n",
       "      <td>70.186855</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00421637202311550012437</td>\n",
       "      <td>15</td>\n",
       "      <td>2739</td>\n",
       "      <td>82.045291</td>\n",
       "      <td>68</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00422637202311677017371</td>\n",
       "      <td>6</td>\n",
       "      <td>1930</td>\n",
       "      <td>76.672493</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00423637202312137826377</td>\n",
       "      <td>17</td>\n",
       "      <td>3294</td>\n",
       "      <td>79.258903</td>\n",
       "      <td>72</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00426637202313170790466</td>\n",
       "      <td>0</td>\n",
       "      <td>2925</td>\n",
       "      <td>71.824968</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Never smoked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
       "0  ID00419637202311204720264      6  3020  70.186855   73  Male     Ex-smoker\n",
       "1  ID00421637202311550012437     15  2739  82.045291   68  Male     Ex-smoker\n",
       "2  ID00422637202311677017371      6  1930  76.672493   73  Male     Ex-smoker\n",
       "3  ID00423637202312137826377     17  3294  79.258903   72  Male     Ex-smoker\n",
       "4  ID00426637202313170790466      0  2925  71.824968   73  Male  Never smoked"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('D:/CSE499/osic-pulmonary-fibrosis-progression/test.csv') \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_test, B_test, P_test, W, FVC, STD, WEEK = {},{},{},{},{},{},{} \n",
    "\n",
    "for p in test.Patient.unique():\n",
    "    x = [] \n",
    "    tab = [] \n",
    "    for i in os.listdir(f'D:/CSE499/osic-pulmonary-fibrosis-progression/test/{p}/'):\n",
    "        x.append(get_img(f'D:/CSE499/osic-pulmonary-fibrosis-progression/test/{p}/{i}')) \n",
    "        tab.append(get_tab(test.loc[test.Patient == p, :])) \n",
    "    tab = np.array(tab) \n",
    "            \n",
    "    x = np.expand_dims(x, axis=-1) \n",
    "    _a = model.predict([x, tab]) \n",
    "    a = np.quantile(_a, q)\n",
    "    A_test[p] = a\n",
    "    B_test[p] = test.FVC.values[test.Patient == p] - a*test.Weeks.values[test.Patient == p]\n",
    "    P_test[p] = test.Percent.values[test.Patient == p] \n",
    "    WEEK[p] = test.Weeks.values[test.Patient == p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sub.Patient_Week.values:\n",
    "    p, w = k.split('_')\n",
    "    w = int(w) \n",
    "    \n",
    "    fvc = A_test[p] * w + B_test[p]\n",
    "    sub.loc[sub.Patient_Week == k, 'FVC'] = fvc\n",
    "    sub.loc[sub.Patient_Week == k, 'Confidence'] = (\n",
    "        P_test[p] - A_test[p] * abs(WEEK[p] - w) \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Week</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00419637202311204720264_-12</td>\n",
       "      <td>3078.462243</td>\n",
       "      <td>128.649098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00421637202311550012437_-12</td>\n",
       "      <td>2819.858889</td>\n",
       "      <td>162.904180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00422637202311677017371_-12</td>\n",
       "      <td>2023.920631</td>\n",
       "      <td>170.593124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00423637202312137826377_-12</td>\n",
       "      <td>3483.026007</td>\n",
       "      <td>268.284910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00426637202313170790466_-12</td>\n",
       "      <td>2968.129965</td>\n",
       "      <td>114.954933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Patient_Week          FVC  Confidence\n",
       "0  ID00419637202311204720264_-12  3078.462243  128.649098\n",
       "1  ID00421637202311550012437_-12  2819.858889  162.904180\n",
       "2  ID00422637202311677017371_-12  2023.920631  170.593124\n",
       "3  ID00423637202312137826377_-12  3483.026007  268.284910\n",
       "4  ID00426637202313170790466_-12  2968.129965  114.954933"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[[\"Patient_Week\",\"FVC\",\"Confidence\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add infos\n"
     ]
    }
   ],
   "source": [
    "ROOT = \"D:/CSE499/osic-pulmonary-fibrosis-progression\"\n",
    "BATCH_SIZE=128\n",
    "\n",
    "tr = pd.read_csv(f\"{ROOT}/train.csv\")\n",
    "tr.drop_duplicates(keep=False, inplace=True, subset=['Patient','Weeks'])\n",
    "chunk = pd.read_csv(f\"{ROOT}/test.csv\")\n",
    "\n",
    "print(\"add infos\")\n",
    "sub = pd.read_csv(f\"{ROOT}/sample_submission.csv\")\n",
    "sub['Patient'] = sub['Patient_Week'].apply(lambda x:x.split('_')[0])\n",
    "sub['Weeks'] = sub['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\n",
    "sub =  sub[['Patient','Weeks','Confidence','Patient_Week']]\n",
    "sub = sub.merge(chunk.drop('Weeks', axis=1), on=\"Patient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr['WHERE'] = 'train'\n",
    "chunk['WHERE'] = 'val'\n",
    "sub['WHERE'] = 'test'\n",
    "data = tr.append([chunk, sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1535, 8) (5, 8) (730, 10) (2270, 10)\n",
      "176 5 5 176\n"
     ]
    }
   ],
   "source": [
    "print(tr.shape, chunk.shape, sub.shape, data.shape)\n",
    "print(tr.Patient.nunique(), chunk.Patient.nunique(), sub.Patient.nunique(), \n",
    "      data.Patient.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['min_week'] = data['Weeks']\n",
    "data.loc[data.WHERE=='test','min_week'] = np.nan\n",
    "data['min_week'] = data.groupby('Patient')['min_week'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = data.loc[data.Weeks == data.min_week]\n",
    "base = base[['Patient','FVC']].copy()\n",
    "base.columns = ['Patient','min_FVC']\n",
    "base['nb'] = 1\n",
    "base['nb'] = base.groupby('Patient')['nb'].transform('cumsum')\n",
    "base = base[base.nb==1]\n",
    "base.drop('nb', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(base, on='Patient', how='left')\n",
    "data['base_week'] = data['Weeks'] - data['min_week']\n",
    "del base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS = ['Sex','SmokingStatus'] #,'Age'\n",
    "FE = []\n",
    "for col in COLS:\n",
    "    for mod in data[col].unique():\n",
    "        FE.append(mod)\n",
    "        data[mod] = (data[col] == mod).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'] = (data['Age'] - data['Age'].min() ) / ( data['Age'].max() - data['Age'].min() )\n",
    "data['BASE'] = (data['min_FVC'] - data['min_FVC'].min() ) / ( data['min_FVC'].max() - data['min_FVC'].min() )\n",
    "data['week'] = (data['base_week'] - data['base_week'].min() ) / ( data['base_week'].max() - data['base_week'].min() )\n",
    "data['percent'] = (data['Percent'] - data['Percent'].min() ) / ( data['Percent'].max() - data['Percent'].min() )\n",
    "FE += ['age','percent','week','BASE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = data.loc[data.WHERE=='train']\n",
    "chunk = data.loc[data.WHERE=='val']\n",
    "sub = data.loc[data.WHERE=='test']\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1535, 22), (5, 22), (730, 22))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.shape, chunk.shape, sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1, C2 = tf.constant(70, dtype='float32'), tf.constant(1000, dtype=\"float32\")\n",
    "\n",
    "def score(y_true, y_pred):\n",
    "    tf.dtypes.cast(y_true, tf.float32)\n",
    "    tf.dtypes.cast(y_pred, tf.float32)\n",
    "    sigma = y_pred[:, 2] - y_pred[:, 0]\n",
    "    fvc_pred = y_pred[:, 1]\n",
    "    \n",
    "    sigma_clip = tf.maximum(sigma, C1)\n",
    "    delta = tf.abs(y_true[:, 0] - fvc_pred)\n",
    "    delta = tf.minimum(delta, C2)\n",
    "    sq2 = tf.sqrt( tf.dtypes.cast(2, dtype=tf.float32) )\n",
    "    metric = (delta / sigma_clip)*sq2 + tf.math.log(sigma_clip* sq2)\n",
    "    return K.mean(metric)\n",
    "\n",
    "def qloss(y_true, y_pred):\n",
    "    qs = [0.2, 0.50, 0.8]\n",
    "    q = tf.constant(np.array([qs]), dtype=tf.float32)\n",
    "    e = y_true - y_pred\n",
    "    v = tf.maximum(q*e, (q-1)*e)\n",
    "    return K.mean(v)\n",
    "\n",
    "def mloss(_lambda):\n",
    "    def loss(y_true, y_pred):\n",
    "        return _lambda * qloss(y_true, y_pred) + (1 - _lambda)*score(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def laplace_log_likelihood(actual_fvc, predicted_fvc, confidence, return_values = False):\n",
    "    \"\"\"\n",
    "    Calculates the modified Laplace Log Likelihood score for this competition.\n",
    "    \"\"\"\n",
    "    sd_clipped = np.maximum(confidence, 70)\n",
    "    delta = np.minimum(np.abs(actual_fvc - predicted_fvc), 1000)\n",
    "    metric = - np.sqrt(2) * delta / sd_clipped - np.log(np.sqrt(2) * sd_clipped)\n",
    "\n",
    "    if return_values:\n",
    "        return metric\n",
    "    else:\n",
    "        return np.mean(metric)\n",
    "\n",
    "def make_model(nh):\n",
    "    z = L.Input((nh,), name=\"Patient\")\n",
    "    x = L.Dense(100, activation=\"relu\", name=\"d1\")(z)\n",
    "    x = L.Dense(100, activation=\"relu\", name=\"d2\")(x)\n",
    "    p1 = L.Dense(3, activation=\"linear\", name=\"p1\")(x)\n",
    "    p2 = L.Dense(3, activation=\"relu\", name=\"p2\")(x)\n",
    "    preds = L.Lambda(lambda x: x[0] + tf.cumsum(x[1], axis=1), \n",
    "                     name=\"preds\")([p1, p2])\n",
    "    \n",
    "    model = M.Model(z, preds, name=\"CNN\")\n",
    "    #model.compile(loss=qloss, optimizer=\"adam\", metrics=[score])\n",
    "    model.compile(loss=mloss(0.8), optimizer=tf.keras.optimizers.Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False), metrics=[score])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET TRAINING DATA AND TARGET VALUE\n",
    "\n",
    "# get target value\n",
    "y  = tr['FVC'].values\n",
    "\n",
    "# get training & test data\n",
    "X_train = tr[FE].values\n",
    "X_test = sub[FE].values\n",
    "\n",
    "\n",
    "nh = X_train.shape[1]\n",
    "\n",
    "# instantiate target arrays\n",
    "train_preds = np.zeros((X_train.shape[0], 3))\n",
    "test_preds = np.zeros((X_test.shape[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Patient (InputLayer)            [(None, 9)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "d1 (Dense)                      (None, 100)          1000        Patient[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "d2 (Dense)                      (None, 100)          10100       d1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "p1 (Dense)                      (None, 3)            303         d2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "p2 (Dense)                      (None, 3)            303         d2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "preds (Lambda)                  (None, 3)            0           p1[0][0]                         \n",
      "                                                                 p2[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 11,706\n",
      "Trainable params: 11,706\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "11706\n"
     ]
    }
   ],
   "source": [
    "net = make_model(nh)\n",
    "print(net.summary())\n",
    "print(net.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "FOLD 2\n",
      "FOLD 3\n",
      "FOLD 4\n",
      "FOLD 5\n"
     ]
    }
   ],
   "source": [
    "model_cnt = 1\n",
    "# instantiate target arrays\n",
    "globals()['train_preds_{}'.format(model_cnt)] = np.zeros((X_train.shape[0], 3))\n",
    "globals()['test_preds_{}'.format(model_cnt)] = np.zeros((X_test.shape[0], 3))\n",
    "\n",
    "NFOLD = 5\n",
    "gkf = GroupKFold(n_splits=NFOLD)\n",
    "groups = tr['Patient'].values\n",
    "\n",
    "cnt = 0\n",
    "EPOCHS = 800\n",
    "BATCH_SIZE=128\n",
    "for tr_idx, val_idx in gkf.split(X_train, y, groups):\n",
    "    cnt += 1\n",
    "    print(f\"FOLD {cnt}\")\n",
    "    net = make_model(nh)\n",
    "    net.fit(X_train[tr_idx], y[tr_idx], batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "            validation_data=(X_train[val_idx], y[val_idx]), verbose=0) #\n",
    "#     print(\"train\", net.evaluate(X_train[tr_idx], y[tr_idx], verbose=0, batch_size=BATCH_SIZE))\n",
    "#     print(\"val\", net.evaluate(X_train[val_idx], y[val_idx], verbose=0, batch_size=BATCH_SIZE))\n",
    "#     print(\"predict val...\")\n",
    "    globals()['train_preds_{}'.format(model_cnt)][val_idx] = net.predict(X_train[val_idx], batch_size=BATCH_SIZE, verbose=0)\n",
    "#     print(\"predict test...\")\n",
    "    globals()['test_preds_{}'.format(model_cnt)] += net.predict(X_test, batch_size=BATCH_SIZE, verbose=0) / NFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Score:  -6.674684477411223\n"
     ]
    }
   ],
   "source": [
    "predicted_fvc = globals()['train_preds_{}'.format(model_cnt)][:,1]\n",
    "confidence = globals()['train_preds_{}'.format(model_cnt)][:,2]-globals()['train_preds_{}'.format(model_cnt)][:,0]\n",
    "model_score = laplace_log_likelihood(actual_fvc = y, predicted_fvc = predicted_fvc, confidence = confidence,\n",
    "                       return_values = False)\n",
    "print('Overall Score: ', model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
