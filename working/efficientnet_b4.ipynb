{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/CSE499/osic-pulmonary-fibrosis-progression/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
       "0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker\n",
       "1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker\n",
       "2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker\n",
       "3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker\n",
       "4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ex-smoker', 'Never smoked', 'Currently smokes'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SmokingStatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tab(df):\n",
    "    \"raturn an array which contains each patient normalized age, sex and smoking status\"\n",
    "    vector = [(df.Age.values[0] - 30) / 30] \n",
    "    \n",
    "    if df.Sex.values[0].lower() == 'male':\n",
    "       vector.append(0)\n",
    "    else:\n",
    "       vector.append(1)\n",
    "    \n",
    "    if df.SmokingStatus.values[0] == 'Never smoked':\n",
    "        vector.extend([0,0])\n",
    "    elif df.SmokingStatus.values[0] == 'Ex-smoker':\n",
    "        vector.extend([1,1])\n",
    "    elif df.SmokingStatus.values[0] == 'Currently smokes':\n",
    "        vector.extend([0,1])\n",
    "    else:\n",
    "        vector.extend([1,0])\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6c01c4dfd74dca850b230a2c262ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Monir\\anaconda3\\envs\\rabbi36\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "A = {} \n",
    "TAB = {} \n",
    "P = [] \n",
    "for i, p in tqdm(enumerate(train.Patient.unique())): # i index, p patient id\n",
    "    sub = train.loc[train.Patient == p, :] # find all data (weeks, FVC, Percent, Age, Sex, SmokingStatus) of a unique patient\n",
    "    fvc = sub.FVC.values # fvc values of the patient during the follow-up\n",
    "    weeks = sub.Weeks.values # follow-up weeks\n",
    "    c = np.vstack([weeks, np.ones(len(weeks))]).T # create an array by the follow-up weeks of shape(len(weeks),2)\n",
    "    a, b = np.linalg.lstsq(c, fvc)[0] # least-square sol, a=gradient matrix, b=right hand matrix \n",
    "    \n",
    "    A[p] = a\n",
    "    TAB[p] = get_tab(sub)\n",
    "    P.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    \"read DICOM dataset and return resize images of size (512,512,1)\"\n",
    "    d = pydicom.dcmread(path) # read and parse the CT scan images (in DICOM format)\n",
    "    resized_image = cv2.resize((d.pixel_array - d.RescaleIntercept) / (d.RescaleSlope * 1000), (512,512))\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class IGenerator(Sequence):\n",
    "    BAD_ID = ['ID00011637202177653955184', 'ID00052637202186188008618']\n",
    "    def __init__(self, keys, a, tab, batch_size):\n",
    "        \"key=patient, a=gradient matrix, tab=a particular patient's data\"\n",
    "        self.keys = [k for k in keys if k not in self.BAD_ID]\n",
    "        self.a = a\n",
    "        self.tab = tab\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_data = {}\n",
    "        for p in train.Patient.values:\n",
    "            self.train_data[p] = os.listdir(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{p}/')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = []\n",
    "        a, tab = [], [] \n",
    "        keys = np.random.choice(self.keys, size = self.batch_size) # randomly chooses n=batch_size number of patients\n",
    "        for k in keys:\n",
    "            try:\n",
    "                i = np.random.choice(self.train_data[k], size=1)[0] # chooses some randomly images for kth patient\n",
    "                img = get_img(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{k}/{i}') # resizes ith image of kth patient\n",
    "                x.append(img) # append kth patient's image data in the list x\n",
    "                a.append(self.a[k]) # append kth patient's gradinet in the list a\n",
    "                tab.append(self.tab[k]) # append kth patient's tabular data in the tab list\n",
    "            except:\n",
    "                print(k, i)\n",
    "       \n",
    "        x,a,tab = np.array(x), np.array(a), np.array(tab) # convert list to array\n",
    "        x = np.expand_dims(x, axis=-1) \n",
    "        return [x, tab] , a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Activation, Flatten, Input, BatchNormalization, GlobalAveragePooling2D, GaussianNoise, \n",
    "    Add, Conv2D, AveragePooling2D, LeakyReLU, Concatenate \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "def get_efficientnet(model, shape):\n",
    "    models_dict = {\n",
    "        'b0': efn.EfficientNetB0(input_shape=shape,weights=None,include_top=False),\n",
    "        'b1': efn.EfficientNetB1(input_shape=shape,weights=None,include_top=False),\n",
    "        'b2': efn.EfficientNetB2(input_shape=shape,weights=None,include_top=False),\n",
    "        'b3': efn.EfficientNetB3(input_shape=shape,weights=None,include_top=False),\n",
    "        'b4': efn.EfficientNetB4(input_shape=shape,weights=None,include_top=False),\n",
    "        'b5': efn.EfficientNetB5(input_shape=shape,weights=None,include_top=False),\n",
    "        'b6': efn.EfficientNetB6(input_shape=shape,weights=None,include_top=False),\n",
    "        'b7': efn.EfficientNetB7(input_shape=shape,weights=None,include_top=False)\n",
    "    }\n",
    "    return models_dict[model]\n",
    "\n",
    "def build_model(shape=(512, 512, 1), model_class=None):\n",
    "    inp = Input(shape=shape)\n",
    "    base = get_efficientnet(model_class, shape)\n",
    "    x = base(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    inp2 = Input(shape=(4,)) # indicates that the expected input will be batches of 4-dimensional vectors\n",
    "    x2 = GaussianNoise(0.2)(inp2) # to mitigate overfitting\n",
    "    x = Concatenate()([x, x2]) \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = Dense(1)(x)\n",
    "    model = Model([inp, inp2] , x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-b4 (Model)         (None, 16, 16, 1792) 17672952    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1792)         0           efficientnet-b4[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 4)            0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1796)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1796)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1797        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 17,674,749\n",
      "Trainable params: 17,549,549\n",
      "Non-trainable params: 125,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MODEL_CLASS = 'b4'\n",
    "base_model = build_model(shape=(512, 512, 1), model_class=MODEL_CLASS)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 80\n",
    "LR = 0.001\n",
    "SAVE_BEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8017\n",
      "Epoch 00001: val_loss improved from inf to 15.20673, saving model to C:/Users/Monir/Documents/CSE499/models/EfficientNet/b4_80_epochs.h5\n",
      "32/32 [==============================] - 8s 255ms/step - loss: 3.8017 - val_loss: 15.2067 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2460\n",
      "Epoch 00002: val_loss improved from 15.20673 to 4.39891, saving model to C:/Users/Monir/Documents/CSE499/models/EfficientNet/b4_80_epochs.h5\n",
      "32/32 [==============================] - 13s 393ms/step - loss: 4.2460 - val_loss: 4.3989 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6582\n",
      "Epoch 00003: val_loss improved from 4.39891 to 3.23028, saving model to C:/Users/Monir/Documents/CSE499/models/EfficientNet/b4_80_epochs.h5\n",
      "32/32 [==============================] - 12s 385ms/step - loss: 3.6582 - val_loss: 3.2303 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.6313\n",
      "Epoch 00004: val_loss did not improve from 3.23028\n",
      "32/32 [==============================] - 5s 158ms/step - loss: 5.6313 - val_loss: 4.2716 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8949\n",
      "Epoch 00005: val_loss did not improve from 3.23028\n",
      "32/32 [==============================] - 5s 144ms/step - loss: 4.8949 - val_loss: 3.6612 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.6304\n",
      "Epoch 00006: val_loss did not improve from 3.23028\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 5.6304 - val_loss: 4.5560 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3776\n",
      "Epoch 00007: val_loss did not improve from 3.23028\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 4.3776 - val_loss: 5.6684 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.4216\n",
      "Epoch 00008: val_loss did not improve from 3.23028\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 5.4216 - val_loss: 6.3860 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.5472\n",
      "Epoch 00009: val_loss improved from 3.23028 to 2.53485, saving model to C:/Users/Monir/Documents/CSE499/models/EfficientNet/b4_80_epochs.h5\n",
      "32/32 [==============================] - 12s 367ms/step - loss: 5.5472 - val_loss: 2.5349 - lr: 5.0000e-04\n",
      "Epoch 10/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 6.0238\n",
      "Epoch 00010: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 5s 142ms/step - loss: 6.0238 - val_loss: 22.8021 - lr: 5.0000e-04\n",
      "Epoch 11/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5477\n",
      "Epoch 00011: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 3.5477 - val_loss: 19.5112 - lr: 5.0000e-04\n",
      "Epoch 12/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2499\n",
      "Epoch 00012: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 4.2499 - val_loss: 12.1392 - lr: 5.0000e-04\n",
      "Epoch 13/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7730\n",
      "Epoch 00013: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 4.7730 - val_loss: 9.5771 - lr: 5.0000e-04\n",
      "Epoch 14/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2984\n",
      "Epoch 00014: val_loss did not improve from 2.53485\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 3.2984 - val_loss: 25.1224 - lr: 5.0000e-04\n",
      "Epoch 15/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8725\n",
      "Epoch 00015: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 3.8725 - val_loss: 35.9529 - lr: 2.5000e-04\n",
      "Epoch 16/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1676\n",
      "Epoch 00016: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 4.1676 - val_loss: 143.5236 - lr: 2.5000e-04\n",
      "Epoch 17/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4429\n",
      "Epoch 00017: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 4.4429 - val_loss: 34.8974 - lr: 2.5000e-04\n",
      "Epoch 18/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2428\n",
      "Epoch 00018: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 4.2428 - val_loss: 54.4279 - lr: 2.5000e-04\n",
      "Epoch 19/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.2725\n",
      "Epoch 00019: val_loss did not improve from 2.53485\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 5.2725 - val_loss: 59.8142 - lr: 2.5000e-04\n",
      "Epoch 20/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8316\n",
      "Epoch 00020: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 3.8316 - val_loss: 40.8591 - lr: 1.2500e-04\n",
      "Epoch 21/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 6.3991\n",
      "Epoch 00021: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 6.3991 - val_loss: 45.9813 - lr: 1.2500e-04\n",
      "Epoch 22/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4072\n",
      "Epoch 00022: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 4.4072 - val_loss: 43.2763 - lr: 1.2500e-04\n",
      "Epoch 23/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9376\n",
      "Epoch 00023: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 4.9376 - val_loss: 50.6908 - lr: 1.2500e-04\n",
      "Epoch 24/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0302\n",
      "Epoch 00024: val_loss did not improve from 2.53485\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 4.0302 - val_loss: 39.6844 - lr: 1.2500e-04\n",
      "Epoch 25/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9079\n",
      "Epoch 00025: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 3.9079 - val_loss: 53.4062 - lr: 6.2500e-05\n",
      "Epoch 26/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7016\n",
      "Epoch 00026: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 3.7016 - val_loss: 26.0791 - lr: 6.2500e-05\n",
      "Epoch 27/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8906\n",
      "Epoch 00027: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 4.8906 - val_loss: 18.6503 - lr: 6.2500e-05\n",
      "Epoch 28/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 6.0403\n",
      "Epoch 00028: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 6.0403 - val_loss: 37.9445 - lr: 6.2500e-05\n",
      "Epoch 29/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0162\n",
      "Epoch 00029: val_loss did not improve from 2.53485\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 4.0162 - val_loss: 31.9145 - lr: 6.2500e-05\n",
      "Epoch 30/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5808\n",
      "Epoch 00030: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 5s 141ms/step - loss: 3.5808 - val_loss: 47.2061 - lr: 3.1250e-05\n",
      "Epoch 31/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0131\n",
      "Epoch 00031: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 5s 143ms/step - loss: 5.0131 - val_loss: 38.8467 - lr: 3.1250e-05\n",
      "Epoch 32/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0371\n",
      "Epoch 00032: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 5.0371 - val_loss: 16.5526 - lr: 3.1250e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.6876\n",
      "Epoch 00033: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 5.6876 - val_loss: 21.2108 - lr: 3.1250e-05\n",
      "Epoch 34/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9761\n",
      "Epoch 00034: val_loss did not improve from 2.53485\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "32/32 [==============================] - 5s 141ms/step - loss: 3.9761 - val_loss: 35.6660 - lr: 3.1250e-05\n",
      "Epoch 35/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.1091\n",
      "Epoch 00035: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 3.1091 - val_loss: 24.5072 - lr: 1.5625e-05\n",
      "Epoch 36/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 6.0524\n",
      "Epoch 00036: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 6.0524 - val_loss: 22.0650 - lr: 1.5625e-05\n",
      "Epoch 37/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0197\n",
      "Epoch 00037: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 5.0197 - val_loss: 38.2897 - lr: 1.5625e-05\n",
      "Epoch 38/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6888\n",
      "Epoch 00038: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 3.6888 - val_loss: 57.9509 - lr: 1.5625e-05\n",
      "Epoch 39/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2392\n",
      "Epoch 00039: val_loss did not improve from 2.53485\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 4.2392 - val_loss: 45.3925 - lr: 1.5625e-05\n",
      "Epoch 40/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5110\n",
      "Epoch 00040: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 4.5110 - val_loss: 46.7899 - lr: 7.8125e-06\n",
      "Epoch 41/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4820\n",
      "Epoch 00041: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 4.4820 - val_loss: 43.4197 - lr: 7.8125e-06\n",
      "Epoch 42/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8220\n",
      "Epoch 00042: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 4.8220 - val_loss: 28.8749 - lr: 7.8125e-06\n",
      "Epoch 43/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7463\n",
      "Epoch 00043: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 3.7463 - val_loss: 39.5461 - lr: 7.8125e-06\n",
      "Epoch 44/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.6902\n",
      "Epoch 00044: val_loss did not improve from 2.53485\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 5.6902 - val_loss: 34.6056 - lr: 7.8125e-06\n",
      "Epoch 45/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.1660\n",
      "Epoch 00045: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 3.1660 - val_loss: 48.8321 - lr: 3.9063e-06\n",
      "Epoch 46/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4025\n",
      "Epoch 00046: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 4.4025 - val_loss: 27.7365 - lr: 3.9063e-06\n",
      "Epoch 47/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.6928\n",
      "Epoch 00047: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 5.6928 - val_loss: 25.8280 - lr: 3.9063e-06\n",
      "Epoch 48/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 6.2863\n",
      "Epoch 00048: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 6.2863 - val_loss: 38.2719 - lr: 3.9063e-06\n",
      "Epoch 49/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 6.0032\n",
      "Epoch 00049: val_loss did not improve from 2.53485\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 6.0032 - val_loss: 42.5563 - lr: 3.9063e-06\n",
      "Epoch 50/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.1777\n",
      "Epoch 00050: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 3.1777 - val_loss: 18.9848 - lr: 1.9531e-06\n",
      "Epoch 51/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.5797\n",
      "Epoch 00051: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 5.5797 - val_loss: 28.8521 - lr: 1.9531e-06\n",
      "Epoch 52/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6974\n",
      "Epoch 00052: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 3.6974 - val_loss: 38.7310 - lr: 1.9531e-06\n",
      "Epoch 53/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7767\n",
      "Epoch 00053: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 4.7767 - val_loss: 50.9383 - lr: 1.9531e-06\n",
      "Epoch 54/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2774\n",
      "Epoch 00054: val_loss did not improve from 2.53485\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 4.2774 - val_loss: 44.8062 - lr: 1.9531e-06\n",
      "Epoch 55/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2002\n",
      "Epoch 00055: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 5s 143ms/step - loss: 3.2002 - val_loss: 43.8973 - lr: 9.7656e-07\n",
      "Epoch 56/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6749\n",
      "Epoch 00056: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 4.6749 - val_loss: 34.1788 - lr: 9.7656e-07\n",
      "Epoch 57/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9321\n",
      "Epoch 00057: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 5s 141ms/step - loss: 3.9321 - val_loss: 62.8184 - lr: 9.7656e-07\n",
      "Epoch 58/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.6417\n",
      "Epoch 00058: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 2.6417 - val_loss: 83.7221 - lr: 9.7656e-07\n",
      "Epoch 59/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.7066\n",
      "Epoch 00059: val_loss did not improve from 2.53485\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "32/32 [==============================] - 4s 139ms/step - loss: 5.7066 - val_loss: 42.6122 - lr: 9.7656e-07\n",
      "Epoch 60/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.0804\n",
      "Epoch 00060: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 3.0804 - val_loss: 77.8050 - lr: 4.8828e-07\n",
      "Epoch 61/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.5492\n",
      "Epoch 00061: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 5.5492 - val_loss: 41.5077 - lr: 4.8828e-07\n",
      "Epoch 62/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6152\n",
      "Epoch 00062: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 3.6152 - val_loss: 53.4255 - lr: 4.8828e-07\n",
      "Epoch 63/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3393\n",
      "Epoch 00063: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 4.3393 - val_loss: 28.6376 - lr: 4.8828e-07\n",
      "Epoch 64/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.8686\n",
      "Epoch 00064: val_loss did not improve from 2.53485\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 2.8686 - val_loss: 34.2122 - lr: 4.8828e-07\n",
      "Epoch 65/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5202\n",
      "Epoch 00065: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 4.5202 - val_loss: 15.8469 - lr: 2.4414e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.0847\n",
      "Epoch 00066: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 3.0847 - val_loss: 77.6746 - lr: 2.4414e-07\n",
      "Epoch 67/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6812\n",
      "Epoch 00067: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 4.6812 - val_loss: 55.9328 - lr: 2.4414e-07\n",
      "Epoch 68/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1808\n",
      "Epoch 00068: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 4.1808 - val_loss: 26.8308 - lr: 2.4414e-07\n",
      "Epoch 69/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0143\n",
      "Epoch 00069: val_loss did not improve from 2.53485\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 4.0143 - val_loss: 66.5892 - lr: 2.4414e-07\n",
      "Epoch 70/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3844\n",
      "Epoch 00070: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 3.3844 - val_loss: 62.8473 - lr: 1.2207e-07\n",
      "Epoch 71/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9189\n",
      "Epoch 00071: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 140ms/step - loss: 3.9189 - val_loss: 40.7413 - lr: 1.2207e-07\n",
      "Epoch 72/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0819\n",
      "Epoch 00072: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 5s 142ms/step - loss: 4.0819 - val_loss: 35.3905 - lr: 1.2207e-07\n",
      "Epoch 73/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8256\n",
      "Epoch 00073: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 4.8256 - val_loss: 40.8315 - lr: 1.2207e-07\n",
      "Epoch 74/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8365\n",
      "Epoch 00074: val_loss did not improve from 2.53485\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 4.8365 - val_loss: 47.9854 - lr: 1.2207e-07\n",
      "Epoch 75/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3349\n",
      "Epoch 00075: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 3.3349 - val_loss: 16.2827 - lr: 6.1035e-08\n",
      "Epoch 76/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.4283\n",
      "Epoch 00076: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 5.4283 - val_loss: 29.9421 - lr: 6.1035e-08\n",
      "Epoch 77/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8590\n",
      "Epoch 00077: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 3.8590 - val_loss: 38.7925 - lr: 6.1035e-08\n",
      "Epoch 78/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.9070\n",
      "Epoch 00078: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 2.9070 - val_loss: 33.1114 - lr: 6.1035e-08\n",
      "Epoch 79/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6376\n",
      "Epoch 00079: val_loss did not improve from 2.53485\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 3.6376 - val_loss: 19.9099 - lr: 6.1035e-08\n",
      "Epoch 80/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0884\n",
      "Epoch 00080: val_loss did not improve from 2.53485\n",
      "32/32 [==============================] - 4s 138ms/step - loss: 4.0884 - val_loss: 49.7717 - lr: 3.0518e-08\n",
      "Training Complete!!!\n"
     ]
    }
   ],
   "source": [
    "P = np.array(P)\n",
    "subs = []\n",
    "folds_history = []\n",
    "\n",
    "\"\"\"\n",
    "er = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",min_delta=1e-3,patience=15,verbose=1,mode=\"auto\",baseline=None,\n",
    "      restore_best_weights=True,) #Stop training when a monitored metric has stopped improving.\n",
    "\"\"\"\n",
    "\n",
    "cpt = tf.keras.callbacks.ModelCheckpoint(filepath=f'C:/Users/Monir/Documents/CSE499/models/EfficientNet/{MODEL_CLASS}_{EPOCHS}_epochs.h5',monitor='val_loss',verbose=1, \n",
    "    save_best_only=SAVE_BEST,mode='auto') #to save model or weights in a checkpoint file at lowest validation loss\n",
    "\n",
    "rlp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=5, verbose=1, min_lr=1e-8) \n",
    "     #Reduce learning rate when a metric has stopped improving.\n",
    "     # if improvement stops, after 5 epochs learning rate will be reduced\n",
    "\n",
    "model = build_model(model_class=MODEL_CLASS)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss=\"mae\") \n",
    "history = model.fit(IGenerator(keys=P, a = A, tab = TAB, batch_size=BATCH_SIZE), \n",
    "                    steps_per_epoch = 32,\n",
    "                    validation_data=IGenerator(keys=P, a = A, tab = TAB, batch_size=BATCH_SIZE),\n",
    "                    validation_steps = 32, \n",
    "                    callbacks = [cpt, rlp], \n",
    "                    epochs=EPOCHS)\n",
    "folds_history.append(history.history)\n",
    "print('Training Complete!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "# save to json:  \n",
    "hist_json_file = 'EffNet_b4_80_epoch_history.json' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)\n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = 'EffNet_b4_80_epoch_history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = 'C:/Users/Monir/Documents/CSE499/results_and_figures/EfficientNet/B4/'\n",
    "\n",
    "import tikzplotlib\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(EPOCHS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_range, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.savefig(result_dir + 'b4_80_epoch_oss.png')\n",
    "plt.savefig(result_dir + 'b4_80_epoch_loss.pdf', dpi=150)\n",
    "tikzplotlib.save(result_dir + 'b4_80_epoch_loss.tex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.9):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_range = range(20,EPOCHS)\n",
    "\n",
    "plt.plot(epochs_range,\n",
    "         smooth_curve(loss[20:]), 'bo', label='Training loss')\n",
    "plt.plot(epochs_range,\n",
    "         smooth_curve(val_loss[20:]), 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.savefig(result_dir + 'b4_80_epoch_loss_smooth.png')\n",
    "plt.savefig(result_dir + 'b4_80_epoch_smooth.pdf', dpi=150)\n",
    "tikzplotlib.save(result_dir + 'b4_80_epoch_smooth.tex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
