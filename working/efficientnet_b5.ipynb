{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('D:/CSE499/osic-pulmonary-fibrosis-progression/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
       "0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker\n",
       "1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker\n",
       "2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker\n",
       "3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker\n",
       "4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ex-smoker', 'Never smoked', 'Currently smokes'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SmokingStatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tab(df):\n",
    "    \"raturn an array which contains each patient normalized age, sex and smoking status\"\n",
    "    vector = [(df.Age.values[0] - 30) / 30] \n",
    "    \n",
    "    if df.Sex.values[0].lower() == 'male':\n",
    "       vector.append(0)\n",
    "    else:\n",
    "       vector.append(1)\n",
    "    \n",
    "    if df.SmokingStatus.values[0] == 'Never smoked':\n",
    "        vector.extend([0,0])\n",
    "    elif df.SmokingStatus.values[0] == 'Ex-smoker':\n",
    "        vector.extend([1,1])\n",
    "    elif df.SmokingStatus.values[0] == 'Currently smokes':\n",
    "        vector.extend([0,1])\n",
    "    else:\n",
    "        vector.extend([1,0])\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae431dc9e73a463fa0ee1e93e8e291d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Monir\\anaconda3\\envs\\rabbi36\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "A = {} \n",
    "TAB = {} \n",
    "P = [] \n",
    "for i, p in tqdm(enumerate(train.Patient.unique())): # i index, p patient id\n",
    "    sub = train.loc[train.Patient == p, :] # find all data (weeks, FVC, Percent, Age, Sex, SmokingStatus) of a unique patient\n",
    "    fvc = sub.FVC.values # fvc values of the patient during the follow-up\n",
    "    weeks = sub.Weeks.values # follow-up weeks\n",
    "    c = np.vstack([weeks, np.ones(len(weeks))]).T # create an array by the follow-up weeks of shape(len(weeks),2)\n",
    "    a, b = np.linalg.lstsq(c, fvc)[0] # least-square sol, a=gradient matrix, b=right hand matrix \n",
    "    \n",
    "    A[p] = a\n",
    "    TAB[p] = get_tab(sub)\n",
    "    P.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    \"read DICOM dataset and return resize images of size (512,512,1)\"\n",
    "    d = pydicom.dcmread(path) # read and parse the CT scan images (in DICOM format)\n",
    "    resized_image = cv2.resize((d.pixel_array - d.RescaleIntercept) / (d.RescaleSlope * 1000), (512,512))\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class IGenerator(Sequence):\n",
    "    BAD_ID = ['ID00011637202177653955184', 'ID00052637202186188008618']\n",
    "    def __init__(self, keys, a, tab, batch_size):\n",
    "        \"key=patient, a=gradient matrix, tab=a particular patient's data\"\n",
    "        self.keys = [k for k in keys if k not in self.BAD_ID]\n",
    "        self.a = a\n",
    "        self.tab = tab\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_data = {}\n",
    "        for p in train.Patient.values:\n",
    "            self.train_data[p] = os.listdir(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{p}/')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = []\n",
    "        a, tab = [], [] \n",
    "        keys = np.random.choice(self.keys, size = self.batch_size) # randomly chooses n=batch_size number of patients\n",
    "        for k in keys:\n",
    "            try:\n",
    "                i = np.random.choice(self.train_data[k], size=1)[0] # chooses some randomly images for kth patient\n",
    "                img = get_img(f'D:/CSE499/osic-pulmonary-fibrosis-progression/train/{k}/{i}') # resizes ith image of kth patient\n",
    "                x.append(img) # append kth patient's image data in the list x\n",
    "                a.append(self.a[k]) # append kth patient's gradinet in the list a\n",
    "                tab.append(self.tab[k]) # append kth patient's tabular data in the tab list\n",
    "            except:\n",
    "                print(k, i)\n",
    "       \n",
    "        x,a,tab = np.array(x), np.array(a), np.array(tab) # convert list to array\n",
    "        x = np.expand_dims(x, axis=-1) \n",
    "        return [x, tab] , a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Activation, Flatten, Input, BatchNormalization, GlobalAveragePooling2D, GaussianNoise, \n",
    "    Add, Conv2D, AveragePooling2D, LeakyReLU, Concatenate \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "def get_efficientnet(model, shape):\n",
    "    models_dict = {\n",
    "        'b0': efn.EfficientNetB0(input_shape=shape,weights=None,include_top=False),\n",
    "        'b1': efn.EfficientNetB1(input_shape=shape,weights=None,include_top=False),\n",
    "        'b2': efn.EfficientNetB2(input_shape=shape,weights=None,include_top=False),\n",
    "        'b3': efn.EfficientNetB3(input_shape=shape,weights=None,include_top=False),\n",
    "        'b4': efn.EfficientNetB4(input_shape=shape,weights=None,include_top=False),\n",
    "        'b5': efn.EfficientNetB5(input_shape=shape,weights=None,include_top=False),\n",
    "        'b6': efn.EfficientNetB6(input_shape=shape,weights=None,include_top=False),\n",
    "        'b7': efn.EfficientNetB7(input_shape=shape,weights=None,include_top=False)\n",
    "    }\n",
    "    return models_dict[model]\n",
    "\n",
    "def build_model(shape=(512, 512, 1), model_class=None):\n",
    "    inp = Input(shape=shape)\n",
    "    base = get_efficientnet(model_class, shape)\n",
    "    x = base(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    inp2 = Input(shape=(4,)) # indicates that the expected input will be batches of 4-dimensional vectors\n",
    "    x2 = GaussianNoise(0.2)(inp2) # to mitigate overfitting\n",
    "    x = Concatenate()([x, x2]) \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = Dense(1)(x)\n",
    "    model = Model([inp, inp2] , x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet-b5 (Model)         (None, 16, 16, 2048) 28512656    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           efficientnet-b5[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gaussian_noise (GaussianNoise)  (None, 4)            0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2052)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 gaussian_noise[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2052)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            2053        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 28,514,709\n",
      "Trainable params: 28,341,973\n",
      "Non-trainable params: 172,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MODEL_CLASS = 'b5'\n",
    "base_model = build_model(shape=(512, 512, 1), model_class=MODEL_CLASS)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 80\n",
    "LR = 0.001\n",
    "SAVE_BEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3317\n",
      "Epoch 00001: val_loss improved from inf to 6.05389, saving model to C:/Users/Monir/Documents/CSE499/models/EfficientNet/b5_80_epochs.h5\n",
      "32/32 [==============================] - 11s 347ms/step - loss: 4.3317 - val_loss: 6.0539 - lr: 0.0010\n",
      "Epoch 2/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6995\n",
      "Epoch 00002: val_loss did not improve from 6.05389\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 4.6995 - val_loss: 15.3554 - lr: 0.0010\n",
      "Epoch 3/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2576\n",
      "Epoch 00003: val_loss did not improve from 6.05389\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 4.2576 - val_loss: 8.2517 - lr: 0.0010\n",
      "Epoch 4/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3540\n",
      "Epoch 00004: val_loss did not improve from 6.05389\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 4.3540 - val_loss: 83.1189 - lr: 0.0010\n",
      "Epoch 5/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1061\n",
      "Epoch 00005: val_loss did not improve from 6.05389\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 4.1061 - val_loss: 7.5399 - lr: 0.0010\n",
      "Epoch 6/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3111\n",
      "Epoch 00006: val_loss improved from 6.05389 to 3.22802, saving model to C:/Users/Monir/Documents/CSE499/models/EfficientNet/b5_80_epochs.h5\n",
      "32/32 [==============================] - 17s 525ms/step - loss: 4.3111 - val_loss: 3.2280 - lr: 0.0010\n",
      "Epoch 7/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8843\n",
      "Epoch 00007: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 3.8843 - val_loss: 4.4344 - lr: 0.0010\n",
      "Epoch 8/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.7588\n",
      "Epoch 00008: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 5.7588 - val_loss: 117.8886 - lr: 0.0010\n",
      "Epoch 9/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0261\n",
      "Epoch 00009: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 198ms/step - loss: 5.0261 - val_loss: 497.5429 - lr: 0.0010\n",
      "Epoch 10/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8019- ETA: 2s -\n",
      "Epoch 00010: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 4.8019 - val_loss: 7.4310 - lr: 0.0010\n",
      "Epoch 11/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.8385\n",
      "Epoch 00011: val_loss did not improve from 3.22802\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 5.8385 - val_loss: 5.1501 - lr: 0.0010\n",
      "Epoch 12/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6720\n",
      "Epoch 00012: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 3.6720 - val_loss: 6.9199 - lr: 5.0000e-04\n",
      "Epoch 13/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3966\n",
      "Epoch 00013: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 3.3966 - val_loss: 117.7733 - lr: 5.0000e-04\n",
      "Epoch 14/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6138\n",
      "Epoch 00014: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 3.6138 - val_loss: 23.4571 - lr: 5.0000e-04\n",
      "Epoch 15/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.0042\n",
      "Epoch 00015: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 3.0042 - val_loss: 201.8057 - lr: 5.0000e-04\n",
      "Epoch 16/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7087\n",
      "Epoch 00016: val_loss did not improve from 3.22802\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 4.7087 - val_loss: 2162.7727 - lr: 5.0000e-04\n",
      "Epoch 17/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6292\n",
      "Epoch 00017: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 4.6292 - val_loss: 1453.2699 - lr: 2.5000e-04\n",
      "Epoch 18/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2546\n",
      "Epoch 00018: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 4.2546 - val_loss: 450.3530 - lr: 2.5000e-04\n",
      "Epoch 19/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6619\n",
      "Epoch 00019: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 4.6619 - val_loss: 793.5850 - lr: 2.5000e-04\n",
      "Epoch 20/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5805\n",
      "Epoch 00020: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 4.5805 - val_loss: 1759.3213 - lr: 2.5000e-04\n",
      "Epoch 21/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3334\n",
      "Epoch 00021: val_loss did not improve from 3.22802\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 4.3334 - val_loss: 983.4017 - lr: 2.5000e-04\n",
      "Epoch 22/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.2982\n",
      "Epoch 00022: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 5.2982 - val_loss: 1056.9724 - lr: 1.2500e-04\n",
      "Epoch 23/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4164\n",
      "Epoch 00023: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 3.4164 - val_loss: 544.8888 - lr: 1.2500e-04\n",
      "Epoch 24/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.5377\n",
      "Epoch 00024: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 5.5377 - val_loss: 845.0833 - lr: 1.2500e-04\n",
      "Epoch 25/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2772- ETA: 0s - loss: 3\n",
      "Epoch 00025: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 3.2772 - val_loss: 488.6266 - lr: 1.2500e-04\n",
      "Epoch 26/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4447\n",
      "Epoch 00026: val_loss did not improve from 3.22802\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 4.4447 - val_loss: 723.3708 - lr: 1.2500e-04\n",
      "Epoch 27/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6050\n",
      "Epoch 00027: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 3.6050 - val_loss: 690.2113 - lr: 6.2500e-05\n",
      "Epoch 28/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.1576\n",
      "Epoch 00028: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 5.1576 - val_loss: 324.0746 - lr: 6.2500e-05\n",
      "Epoch 29/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6192\n",
      "Epoch 00029: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 4.6192 - val_loss: 649.2802 - lr: 6.2500e-05\n",
      "Epoch 30/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8375\n",
      "Epoch 00030: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 197ms/step - loss: 3.8375 - val_loss: 524.9744 - lr: 6.2500e-05\n",
      "Epoch 31/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6949\n",
      "Epoch 00031: val_loss did not improve from 3.22802\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 4.6949 - val_loss: 666.2817 - lr: 6.2500e-05\n",
      "Epoch 32/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3518\n",
      "Epoch 00032: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 4.3518 - val_loss: 700.3981 - lr: 3.1250e-05\n",
      "Epoch 33/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5864\n",
      "Epoch 00033: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 197ms/step - loss: 3.5864 - val_loss: 622.1858 - lr: 3.1250e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2847\n",
      "Epoch 00034: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 4.2847 - val_loss: 1089.4734 - lr: 3.1250e-05\n",
      "Epoch 35/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9633\n",
      "Epoch 00035: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 4.9633 - val_loss: 436.8795 - lr: 3.1250e-05\n",
      "Epoch 36/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.4552\n",
      "Epoch 00036: val_loss did not improve from 3.22802\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "32/32 [==============================] - 6s 199ms/step - loss: 5.4552 - val_loss: 897.2300 - lr: 3.1250e-05\n",
      "Epoch 37/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0259\n",
      "Epoch 00037: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 4.0259 - val_loss: 657.2283 - lr: 1.5625e-05\n",
      "Epoch 38/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4629\n",
      "Epoch 00038: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 199ms/step - loss: 4.4629 - val_loss: 484.6355 - lr: 1.5625e-05\n",
      "Epoch 39/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0244\n",
      "Epoch 00039: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 198ms/step - loss: 4.0244 - val_loss: 571.4733 - lr: 1.5625e-05\n",
      "Epoch 40/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.3233\n",
      "Epoch 00040: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 5.3233 - val_loss: 644.9756 - lr: 1.5625e-05\n",
      "Epoch 41/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5287\n",
      "Epoch 00041: val_loss did not improve from 3.22802\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 4.5287 - val_loss: 536.8306 - lr: 1.5625e-05\n",
      "Epoch 42/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7525\n",
      "Epoch 00042: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 198ms/step - loss: 3.7525 - val_loss: 546.2288 - lr: 7.8125e-06\n",
      "Epoch 43/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3942\n",
      "Epoch 00043: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 198ms/step - loss: 4.3942 - val_loss: 472.0010 - lr: 7.8125e-06\n",
      "Epoch 44/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5134\n",
      "Epoch 00044: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 4.5134 - val_loss: 303.7190 - lr: 7.8125e-06\n",
      "Epoch 45/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8359\n",
      "Epoch 00045: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 4.8359 - val_loss: 439.1844 - lr: 7.8125e-06\n",
      "Epoch 46/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2487\n",
      "Epoch 00046: val_loss did not improve from 3.22802\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 4.2487 - val_loss: 290.4985 - lr: 7.8125e-06\n",
      "Epoch 47/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.0800\n",
      "Epoch 00047: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 3.0800 - val_loss: 246.5665 - lr: 3.9063e-06\n",
      "Epoch 48/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2694\n",
      "Epoch 00048: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 4.2694 - val_loss: 246.6118 - lr: 3.9063e-06\n",
      "Epoch 49/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3153\n",
      "Epoch 00049: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 3.3153 - val_loss: 293.7801 - lr: 3.9063e-06\n",
      "Epoch 50/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.2051\n",
      "Epoch 00050: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 5.2051 - val_loss: 322.5581 - lr: 3.9063e-06\n",
      "Epoch 51/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2417\n",
      "Epoch 00051: val_loss did not improve from 3.22802\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 3.2417 - val_loss: 202.5151 - lr: 3.9063e-06\n",
      "Epoch 52/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3232\n",
      "Epoch 00052: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 3.3232 - val_loss: 575.2086 - lr: 1.9531e-06\n",
      "Epoch 53/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0859\n",
      "Epoch 00053: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 5.0859 - val_loss: 301.5833 - lr: 1.9531e-06\n",
      "Epoch 54/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9301\n",
      "Epoch 00054: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 3.9301 - val_loss: 938.9816 - lr: 1.9531e-06\n",
      "Epoch 55/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.8438\n",
      "Epoch 00055: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 5.8438 - val_loss: 500.6127 - lr: 1.9531e-06\n",
      "Epoch 56/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.4043\n",
      "Epoch 00056: val_loss did not improve from 3.22802\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "32/32 [==============================] - 6s 197ms/step - loss: 5.4043 - val_loss: 379.3278 - lr: 1.9531e-06\n",
      "Epoch 57/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2621\n",
      "Epoch 00057: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 192ms/step - loss: 3.2621 - val_loss: 471.7112 - lr: 9.7656e-07\n",
      "Epoch 58/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7566\n",
      "Epoch 00058: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 3.7566 - val_loss: 269.1281 - lr: 9.7656e-07\n",
      "Epoch 59/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1360\n",
      "Epoch 00059: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 4.1360 - val_loss: 389.0196 - lr: 9.7656e-07\n",
      "Epoch 60/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1258\n",
      "Epoch 00060: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 4.1258 - val_loss: 294.1902 - lr: 9.7656e-07\n",
      "Epoch 61/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3822\n",
      "Epoch 00061: val_loss did not improve from 3.22802\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 3.3822 - val_loss: 392.6079 - lr: 9.7656e-07\n",
      "Epoch 62/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4162- ETA: 0s - loss: 4.13\n",
      "Epoch 00062: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 4.4162 - val_loss: 383.6304 - lr: 4.8828e-07\n",
      "Epoch 63/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8503\n",
      "Epoch 00063: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 4.8503 - val_loss: 465.6519 - lr: 4.8828e-07\n",
      "Epoch 64/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.8944\n",
      "Epoch 00064: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 5.8944 - val_loss: 434.4096 - lr: 4.8828e-07\n",
      "Epoch 65/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5524\n",
      "Epoch 00065: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 3.5524 - val_loss: 652.6515 - lr: 4.8828e-07\n",
      "Epoch 66/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6229\n",
      "Epoch 00066: val_loss did not improve from 3.22802\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "32/32 [==============================] - 6s 197ms/step - loss: 3.6229 - val_loss: 503.2378 - lr: 4.8828e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.2239\n",
      "Epoch 00067: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 5.2239 - val_loss: 203.3911 - lr: 2.4414e-07\n",
      "Epoch 68/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6156\n",
      "Epoch 00068: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 3.6156 - val_loss: 489.0351 - lr: 2.4414e-07\n",
      "Epoch 69/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.5612\n",
      "Epoch 00069: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 192ms/step - loss: 5.5612 - val_loss: 424.2379 - lr: 2.4414e-07\n",
      "Epoch 70/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3972\n",
      "Epoch 00070: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 191ms/step - loss: 4.3972 - val_loss: 383.2021 - lr: 2.4414e-07\n",
      "Epoch 71/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3459\n",
      "Epoch 00071: val_loss did not improve from 3.22802\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 3.3459 - val_loss: 565.8407 - lr: 2.4414e-07\n",
      "Epoch 72/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.2062\n",
      "Epoch 00072: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 192ms/step - loss: 5.2062 - val_loss: 350.0935 - lr: 1.2207e-07\n",
      "Epoch 73/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1517\n",
      "Epoch 00073: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 4.1517 - val_loss: 272.6013 - lr: 1.2207e-07\n",
      "Epoch 74/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7500\n",
      "Epoch 00074: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 3.7500 - val_loss: 279.2110 - lr: 1.2207e-07\n",
      "Epoch 75/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 6.2789\n",
      "Epoch 00075: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 6.2789 - val_loss: 515.3868 - lr: 1.2207e-07\n",
      "Epoch 76/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2090\n",
      "Epoch 00076: val_loss did not improve from 3.22802\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 3.2090 - val_loss: 561.9175 - lr: 1.2207e-07\n",
      "Epoch 77/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4645\n",
      "Epoch 00077: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 3.4645 - val_loss: 663.7283 - lr: 6.1035e-08\n",
      "Epoch 78/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5660\n",
      "Epoch 00078: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 4.5660 - val_loss: 615.4374 - lr: 6.1035e-08\n",
      "Epoch 79/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8460\n",
      "Epoch 00079: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 3.8460 - val_loss: 350.7142 - lr: 6.1035e-08\n",
      "Epoch 80/80\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6946\n",
      "Epoch 00080: val_loss did not improve from 3.22802\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 4.6946 - val_loss: 527.2271 - lr: 6.1035e-08\n",
      "Training Complete!!!\n"
     ]
    }
   ],
   "source": [
    "P = np.array(P)\n",
    "subs = []\n",
    "folds_history = []\n",
    "\n",
    "\"\"\"\n",
    "er = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",min_delta=1e-3,patience=15,verbose=1,mode=\"auto\",baseline=None,\n",
    "      restore_best_weights=True,) #Stop training when a monitored metric has stopped improving.\n",
    "\"\"\"\n",
    "\n",
    "cpt = tf.keras.callbacks.ModelCheckpoint(filepath=f'C:/Users/Monir/Documents/CSE499/models/EfficientNet/{MODEL_CLASS}_{EPOCHS}_epochs.h5',monitor='val_loss',verbose=1, \n",
    "    save_best_only=SAVE_BEST,mode='auto') #to save model or weights in a checkpoint file at lowest validation loss\n",
    "\n",
    "rlp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=5, verbose=1, min_lr=1e-8) \n",
    "     #Reduce learning rate when a metric has stopped improving.\n",
    "     # if improvement stops, after 5 epochs learning rate will be reduced\n",
    "\n",
    "model = build_model(model_class=MODEL_CLASS)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss=\"mae\") \n",
    "history = model.fit(IGenerator(keys=P, a = A, tab = TAB, batch_size=BATCH_SIZE), \n",
    "                    steps_per_epoch = 32,\n",
    "                    validation_data=IGenerator(keys=P, a = A, tab = TAB, batch_size=BATCH_SIZE),\n",
    "                    validation_steps = 32, \n",
    "                    callbacks = [cpt, rlp], \n",
    "                    epochs=EPOCHS)\n",
    "folds_history.append(history.history)\n",
    "print('Training Complete!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "# save to json:  \n",
    "hist_json_file = 'EffNet_b5_80_epoch_history.json' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)\n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = 'EffNet_b5_80_epoch_history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = 'C:/Users/Monir/Documents/CSE499/results_and_figures/EfficientNet/B5/'\n",
    "\n",
    "import tikzplotlib\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(EPOCHS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_range, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.savefig(result_dir + 'b5_80_epoch_oss.png')\n",
    "plt.savefig(result_dir + 'b5_80_epoch_loss.pdf', dpi=150)\n",
    "#tikzplotlib.save(result_dir + 'b5_60_epoch_loss.tex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.8):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_range = range(20,EPOCHS)\n",
    "\n",
    "plt.plot(epochs_range,smooth_curve(loss[20:]), 'bo', label='Training loss')\n",
    "plt.plot(epochs_range,smooth_curve(val_loss[20:]), 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.savefig(result_dir + 'b5_80_epoch_loss_smooth.png')\n",
    "plt.savefig(result_dir + 'b5_80_epoch_smooth.pdf', dpi=150)\n",
    "#tikzplotlib.save(result_dir + 'b5_60_epoch_smooth.tex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
